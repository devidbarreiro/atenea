"""Cliente para Google Lyria Music Generation API (Vertex AI)"""
import logging
from typing import Dict, Optional, List
import requests
import base64
from google.auth import default
from google.auth.transport.requests import Request

logger = logging.getLogger(__name__)

# Importar deep-translator para traducci√≥n obligatoria
try:
    from deep_translator import GoogleTranslator
    TRANSLATOR_AVAILABLE = True
except ImportError:
    TRANSLATOR_AVAILABLE = False
    logger.error("‚ùå deep-translator NO est√° instalado. Instala con: pip install deep-translator")
    raise ImportError(
        "deep-translator es requerido para Google Lyria. "
        "Instala con: pip install deep-translator"
    )

# Modelos disponibles de Lyria
LYRIA_MODELS = {
    'lyria-002': {
        'version': '2.0',
        'description': 'Lyria 2 - Generaci√≥n de m√∫sica instrumental de alta calidad',
        'duration_seconds': 30,  # Fijo: siempre genera clips de 30 segundos
        'sample_rate': 48000,  # 48 kHz
        'format': 'wav',
        'instrumental_only': True,
        'language': 'en-us',  # Solo ingl√©s de EE.UU. para prompts
    },
}


class GoogleLyriaClient:
    """Cliente para Google Lyria Music Generation (Vertex AI)"""
    
    def __init__(self, project_id: str = None, location: str = "us-central1", model_name: str = "lyria-002"):
        """
        Inicializa el cliente de Lyria
        
        Args:
            project_id: ID del proyecto de Google Cloud (si None, se obtiene de settings)
            location: Regi√≥n del endpoint (us-central1, europe-west4, etc.)
            model_name: Modelo a usar (actualmente solo 'lyria-002')
        """
        from django.conf import settings
        
        if model_name not in LYRIA_MODELS:
            raise ValueError(f"Modelo no soportado: {model_name}. Modelos disponibles: {list(LYRIA_MODELS.keys())}")
        
        # Verificar que deep-translator est√© disponible
        if not TRANSLATOR_AVAILABLE:
            raise ImportError(
                "deep-translator es requerido para Google Lyria. "
                "Instala con: pip install deep-translator"
            )
        
        self.project_id = project_id or getattr(settings, 'GCS_PROJECT_ID', None)
        if not self.project_id:
            raise ValueError("project_id es requerido. Configura GCS_PROJECT_ID en settings.")
        
        self.location = location
        self.base_url = f"https://{location}-aiplatform.googleapis.com/v1"
        self.model_name = model_name
        self.model_config = LYRIA_MODELS[model_name]
        
        # No inicializar traductor aqu√≠, se crea por cada traducci√≥n
        pass
        
        # Obtener credenciales con los scopes correctos para Vertex AI
        scopes = ['https://www.googleapis.com/auth/cloud-platform']
        self.credentials, _ = default(scopes=scopes)
        
        logger.info(f"Cliente Lyria inicializado: {self.project_id} @ {location}")
        logger.info(f"Modelo: {model_name} - {self.model_config['description']}")
    
    def _get_access_token(self) -> str:
        """Obtiene un access token v√°lido de Google Cloud"""
        if not self.credentials.valid:
            self.credentials.refresh(Request())
        return self.credentials.token
    
    def _translate_to_english(self, text: str) -> str:
        """
        Traduce el texto al ingl√©s de forma obligatoria.
        Lyria solo acepta prompts en ingl√©s (en-us).
        
        Args:
            text: Texto a traducir
            
        Returns:
            Texto traducido al ingl√©s
            
        Raises:
            ValueError: Si no se puede traducir el texto
        """
        if not text or not text.strip():
            raise ValueError("El texto a traducir no puede estar vac√≠o")
        
        try:
            # Crear instancia del traductor (deep-translator usa Google Translate API gratuita)
            translator = GoogleTranslator(source='auto', target='en')
            
            logger.info(f"üåê Traduciendo prompt a ingl√©s: {text[:50]}...")
            
            # Traducir al ingl√©s de forma obligatoria
            translated_text = translator.translate(text)
            
            if not translated_text or not translated_text.strip():
                raise ValueError(f"No se pudo traducir el texto: '{text}' (resultado vac√≠o)")
            
            # Si el texto traducido es igual al original (o muy similar), probablemente ya estaba en ingl√©s
            if translated_text.strip().lower() == text.strip().lower():
                logger.info(f"‚úì Prompt ya estaba en ingl√©s: {text[:50]}...")
                return text
            
            logger.info(f"‚úì Prompt traducido exitosamente: {translated_text[:100]}...")
            return translated_text
            
        except Exception as e:
            logger.error(f"‚ùå Error al traducir prompt: {e}", exc_info=True)
            raise ValueError(
                f"No se pudo traducir el prompt al ingl√©s. "
                f"Error: {str(e)}. "
                f"Aseg√∫rate de que deep-translator est√© instalado correctamente: pip install deep-translator"
            ) from e
    
    def generate_music(
        self,
        prompt: str,
        negative_prompt: Optional[str] = None,
        seed: Optional[int] = None,
        sample_count: Optional[int] = None,
    ) -> Dict:
        """
        Genera m√∫sica usando Google Lyria
        
        Args:
            prompt: Descripci√≥n de texto del audio a generar (se traducir√° autom√°ticamente al ingl√©s).
                   Ejemplo: "Una canci√≥n ac√∫stica folk tranquila con una melod√≠a suave de guitarra y cuerdas suaves."
            negative_prompt: Opcional. Descripci√≥n de lo que se debe excluir del audio generado.
                           Ejemplo: "voces, tempo lento"
            seed: Opcional. Semilla para generaci√≥n determinista (0-4294967295).
                  No se puede usar con sample_count en la misma solicitud.
            sample_count: Opcional. N√∫mero de muestras de audio a generar (default: 1).
                         No se puede usar con seed en la misma solicitud.
        
        Returns:
            dict con:
                - 'audio_samples': Lista de dicts con 'audio_data' (bytes) y 'mime_type'
                - 'model': Nombre del modelo usado
                - 'model_display_name': Nombre visible del modelo
                - 'deployed_model_id': ID del modelo desplegado (si aplica)
        
        Raises:
            ValueError: Si los par√°metros son inv√°lidos
            Exception: Si la generaci√≥n falla
        """
        try:
            # Validar par√°metros mutuamente excluyentes
            if seed is not None and sample_count is not None:
                raise ValueError("No se puede usar 'seed' y 'sample_count' en la misma solicitud. Usa uno u otro.")
            
            # Validar prompt
            if not prompt or not prompt.strip():
                raise ValueError("El prompt es obligatorio y no puede estar vac√≠o")
            
            # Validar seed si se proporciona
            if seed is not None:
                if not isinstance(seed, int) or seed < 0:
                    raise ValueError("seed debe ser un entero no negativo")
            
            # Validar sample_count si se proporciona
            if sample_count is not None:
                if not isinstance(sample_count, int) or sample_count < 1:
                    raise ValueError("sample_count debe ser un entero mayor a 0")
            
            # TRADUCIR PROMPT AL INGL√âS DE FORMA OBLIGATORIA
            original_prompt = prompt
            prompt = self._translate_to_english(prompt)
            
            # Traducir negative_prompt si existe
            original_negative_prompt = negative_prompt
            if negative_prompt:
                negative_prompt = self._translate_to_english(negative_prompt)
            
            logger.info(f"üéµ Generando m√∫sica con {self.model_name}")
            if prompt != original_prompt:
                logger.info(f"   Prompt original: {original_prompt[:100]}{'...' if len(original_prompt) > 100 else ''}")
            logger.info(f"   Prompt (en): {prompt[:100]}{'...' if len(prompt) > 100 else ''}")
            if negative_prompt:
                if negative_prompt != original_negative_prompt:
                    logger.info(f"   Negative prompt original: {original_negative_prompt[:100]}{'...' if len(original_negative_prompt) > 100 else ''}")
                logger.info(f"   Negative prompt (en): {negative_prompt[:100]}{'...' if len(negative_prompt) > 100 else ''}")
            if seed is not None:
                logger.info(f"   Seed: {seed}")
            if sample_count is not None:
                logger.info(f"   Sample count: {sample_count}")
            
            # Endpoint para predict (s√≠ncrono)
            endpoint = (
                f"{self.base_url}/projects/{self.project_id}/"
                f"locations/{self.location}/publishers/google/"
                f"models/{self.model_name}:predict"
            )
            
            # Preparar instancia
            instance = {
                "prompt": prompt
            }
            
            # Agregar par√°metros opcionales a la instancia
            if negative_prompt:
                instance["negative_prompt"] = negative_prompt
            
            if seed is not None:
                instance["seed"] = seed
            
            # Preparar par√°metros
            parameters = {}
            
            # sample_count va en parameters, no en instances
            if sample_count is not None:
                parameters["sample_count"] = sample_count
            
            payload = {
                "instances": [instance],
                "parameters": parameters
            }
            
            # Log del payload (sin mostrar datos sensibles completos)
            logger.debug(f"üì§ Payload: instances={len(payload['instances'])}, parameters={payload['parameters']}")
            logger.debug(f"üì§ Instance keys: {list(instance.keys())}")
            
            # Headers con autenticaci√≥n
            headers = {
                "Authorization": f"Bearer {self._get_access_token()}",
                "Content-Type": "application/json; charset=utf-8"
            }
            
            logger.info(f"üì§ Enviando request a: {endpoint}")
            
            # Hacer la request (s√≠ncrona)
            response = requests.post(endpoint, json=payload, headers=headers, timeout=120)
            
            logger.info(f"üì• Response status: {response.status_code}")
            logger.debug(f"üì• Response headers: {dict(response.headers)}")
            logger.debug(f"üì• Response text (first 500 chars): {response.text[:500]}")
            
            # Manejar respuesta
            if response.status_code == 200:
                response_data = response.json()
                
                # Log detallado de la respuesta para debugging
                logger.info(f"üì• Response data keys: {list(response_data.keys())}")
                logger.debug(f"üì• Full response: {str(response_data)[:1000]}")  # Primeros 1000 chars
                
                # Verificar si hay errores en la respuesta
                if 'error' in response_data:
                    error_detail = response_data['error']
                    error_code = error_detail.get('code', 'UNKNOWN')
                    error_message = error_detail.get('message', 'Unknown error')
                    raise ValueError(f"Error en respuesta de API: {error_code} - {error_message}")
                
                # Extraer predicciones
                predictions = response_data.get('predictions', [])
                
                if not predictions:
                    logger.error(f"‚ùå No hay predictions en la respuesta. Response keys: {list(response_data.keys())}")
                    logger.error(f"‚ùå Response data: {str(response_data)[:500]}")
                    raise ValueError("La API no devolvi√≥ predicciones de audio")
                
                logger.info(f"üìä N√∫mero de predicciones recibidas: {len(predictions)}")
                
                # Decodificar audio de cada predicci√≥n
                audio_samples = []
                for idx, prediction in enumerate(predictions):
                    logger.debug(f"üìä Predicci√≥n {idx + 1} keys: {list(prediction.keys()) if isinstance(prediction, dict) else 'Not a dict'}")
                    
                    # Intentar diferentes nombres de campo posibles
                    audio_content_b64 = (
                        prediction.get('audioContent') or 
                        prediction.get('audio_content') or
                        prediction.get('bytesBase64Encoded') or
                        prediction.get('bytes_base64_encoded')
                    )
                    mime_type = prediction.get('mimeType') or prediction.get('mime_type', 'audio/wav')
                    
                    if not audio_content_b64:
                        logger.warning(f"‚ö†Ô∏è Predicci√≥n {idx + 1} no contiene audioContent")
                        logger.warning(f"   Predicci√≥n keys: {list(prediction.keys()) if isinstance(prediction, dict) else type(prediction)}")
                        logger.warning(f"   Predicci√≥n sample: {str(prediction)[:200]}")
                        continue
                    
                    # Decodificar base64 a bytes
                    try:
                        audio_data = base64.b64decode(audio_content_b64)
                        audio_samples.append({
                            'audio_data': audio_data,
                            'mime_type': mime_type,
                            'index': idx
                        })
                        logger.info(f"   ‚úì Audio sample {idx + 1} decodificado ({len(audio_data)} bytes)")
                    except Exception as e:
                        logger.error(f"Error decodificando audio sample {idx + 1}: {e}")
                        raise ValueError(f"Error decodificando audio: {str(e)}")
                
                if not audio_samples:
                    logger.error(f"‚ùå No se pudieron decodificar los audios generados")
                    logger.error(f"   N√∫mero de predicciones recibidas: {len(predictions)}")
                    logger.error(f"   Estructura de la primera predicci√≥n: {str(predictions[0])[:500] if predictions else 'No hay predicciones'}")
                    logger.error(f"   Response data completo: {str(response_data)[:1000]}")
                    raise ValueError(
                        f"No se pudieron decodificar los audios generados. "
                        f"Se recibieron {len(predictions)} predicci√≥n(es) pero ninguna conten√≠a audioContent v√°lido. "
                        f"Verifica los logs para m√°s detalles."
                    )
                
                result = {
                    'audio_samples': audio_samples,
                    'model': response_data.get('model', f"projects/{self.project_id}/locations/{self.location}/publishers/google/models/{self.model_name}"),
                    'model_display_name': response_data.get('modelDisplayName', 'Lyria 2'),
                    'deployed_model_id': response_data.get('deployedModelId'),
                    'duration_seconds': self.model_config['duration_seconds'],
                    'sample_rate': self.model_config['sample_rate'],
                    'format': self.model_config['format'],
                }
                
                logger.info(f"‚úÖ M√∫sica generada exitosamente: {len(audio_samples)} muestra(s) de {self.model_config['duration_seconds']}s")
                return result
            else:
                # Parsear el error de Google
                error_msg = response.text
                error_data = None
                
                try:
                    error_data = response.json()
                    if 'error' in error_data:
                        error_detail = error_data['error']
                        error_code = error_detail.get('code', response.status_code)
                        error_message = error_detail.get('message', error_msg)
                        
                        # Detectar errores espec√≠ficos de contenido sensible
                        if 'sensitive words' in error_message.lower() or 'responsible ai' in error_message.lower():
                            logger.error(f"üö´ Contenido bloqueado por filtro de IA Responsable")
                            logger.error(f"   Mensaje: {error_message}")
                            raise ValueError(
                                f"‚ùå Tu prompt fue bloqueado por el filtro de contenido de Google.\n\n"
                                f"Motivo: {error_message}\n\n"
                                f"üí° Sugerencias:\n"
                                f"- Usa prompts detallados: g√©nero, estado de √°nimo, instrumentaci√≥n, tempo\n"
                                f"- Evita contenido violento, sexual o controversial\n"
                                f"- Usa t√©rminos musicales y t√©cnicos\n"
                                f"- El prompt ser√° traducido autom√°ticamente al ingl√©s\n\n"
                                f"Si crees que es un error, contacta a Google con el c√≥digo de soporte en los logs."
                            )
                        
                        # Detectar errores de idioma (no deber√≠a pasar si la traducci√≥n funciona)
                        if 'unsupported language' in error_message.lower() or 'supported languages' in error_message.lower():
                            logger.error(f"‚ùå Error de idioma detectado a pesar de la traducci√≥n")
                            logger.error(f"   Prompt original: {original_prompt}")
                            logger.error(f"   Prompt traducido: {prompt}")
                            logger.error(f"   Mensaje de error: {error_message}")
                            raise ValueError(
                                f"‚ùå Error de idioma detectado por la API de Lyria.\n\n"
                                f"Prompt original: {original_prompt}\n"
                                f"Prompt traducido: {prompt}\n\n"
                                f"Esto no deber√≠a pasar. Por favor, reporta este error.\n"
                                f"Error de API: {error_message}"
                            )
                        
                        error_msg = f"Error {error_code}: {error_message}"
                except (KeyError, TypeError, AttributeError):
                    pass  # Usar mensaje de error gen√©rico si no se puede parsear
                
                logger.error(f"‚ùå Error en Lyria: {error_msg}")
                raise Exception(error_msg)
            
        except Exception as e:
            logger.error(f"‚ùå Error al generar m√∫sica con Lyria: {str(e)}")
            raise

