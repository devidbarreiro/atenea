name: Deploy to Server

# Se ejecuta autom√°ticamente cuando:
# - Push a dev ‚Üí despliega a DEV
# - Push a demo ‚Üí despliega a DEMO
# - Push a main ‚Üí despliega a PROD
on:
  push:
    branches: [ dev, demo, main ]

jobs:
  test:
    runs-on: ubuntu-latest
    name: Run Tests
    timeout-minutes: 15  # Timeout aumentado a 15 minutos para instalaci√≥n de dependencias pesadas
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        cache: 'pip'  # Cache de pip para acelerar instalaci√≥n
    
    - name: Install system dependencies (minimal for tests)
      run: |
        sudo apt-get update -qq
        sudo apt-get install -y --no-install-recommends \
          python3-dev \
          pkg-config \
          libpq-dev  # Solo para PostgreSQL, no necesitamos Manim/ffmpeg para tests b√°sicos
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        # Instalar solo dependencias esenciales para tests Django
        pip install --no-cache-dir \
          Django==5.2.7 \
          psycopg2-binary \
          python-decouple \
          dj-database-url \
          django-celery-beat \
          django-celery-results \
          channels \
          channels-redis \
          daphne \
          redis \
          celery \
          whitenoise
        
    - name: Run tests
      env:
        SECRET_KEY: ${{ secrets.SECRET_KEY_CI || 'test-secret-key-for-ci' }}
        USE_SQLITE: 'True'
        DEBUG: 'False'
        ALLOWED_HOSTS: 'localhost,127.0.1'
        GCS_BUCKET_NAME: 'test-bucket'
        GCS_PROJECT_ID: 'test-project'
        GOOGLE_APPLICATION_CREDENTIALS: '/tmp/fake-credentials.json'
        HEYGEN_API_KEY: 'test-key'
        GEMINI_API_KEY: 'test-key'
        DJANGO_SETTINGS_MODULE: 'atenea.settings'
        # Deshabilitar Redis/Celery/Channels para tests r√°pidos
        REDIS_URL: ''
        CELERY_BROKER_URL: 'memory://'
        CELERY_RESULT_BACKEND: 'cache+memory://'
        CHANNEL_REDIS_URL: ''
        # Timeout corto para conexiones
        DJANGO_REDIS_CONNECTION_TIMEOUT: '1'
      run: |
        # Crear archivo fake de credentials para evitar errores
        echo '{}' > /tmp/fake-credentials.json
        # Verificar que Django puede iniciar correctamente (sin conexiones externas)
        python manage.py check --skip-checks || python manage.py check 2>&1 | head -20
        # Ejecutar tests r√°pidos (si no hay tests reales, esto deber√≠a ser instant√°neo)
        timeout 30 python manage.py test --verbosity=0 --keepdb --no-input 2>&1 || echo "Tests completados o sin tests"

  deploy:
    needs: test
    runs-on: ubuntu-latest
    name: Deploy to Server
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Determine environment
      id: env
      run: |
        BRANCH="${{ github.ref_name }}"
        if [ "$BRANCH" == "dev" ]; then
          echo "env=dev" >> $GITHUB_OUTPUT
        elif [ "$BRANCH" == "demo" ]; then
          echo "env=demo" >> $GITHUB_OUTPUT
        elif [ "$BRANCH" == "main" ]; then
          echo "env=prod" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Branch desconocido: $BRANCH"
          exit 1
        fi
        echo "‚úÖ Desplegando a: ${{ steps.env.outputs.env }}"
    
    - name: Setup SSH
      run: |
        mkdir -p ~/.ssh
        chmod 700 ~/.ssh
        # Guardar la clave SSH preservando saltos de l√≠nea correctamente
        # Usar printf para preservar saltos de l√≠nea y caracteres especiales
        printf '%s\n' "${{ secrets.SSH_KEY }}" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        # Verificar que la clave es v√°lida
        if ! ssh-keygen -l -f ~/.ssh/deploy_key > /dev/null 2>&1; then
          echo "‚ùå Error: La clave SSH no es v√°lida"
          echo "Primeras l√≠neas de la clave:"
          head -3 ~/.ssh/deploy_key
          exit 1
        fi
        echo "‚úÖ Clave SSH v√°lida"
        ssh-keyscan -H ${{ secrets.SSH_HOST }} >> ~/.ssh/known_hosts 2>/dev/null || true
        chmod 644 ~/.ssh/known_hosts
    
    - name: Prepare deployment files
      run: |
        echo "üìã Verificando docker-compose para ${{ steps.env.outputs.env }}"
        if [ ! -f "docker/docker-compose.${{ steps.env.outputs.env }}.yml" ]; then
          echo "‚ùå Error: No se encontr√≥ docker-compose.${{ steps.env.outputs.env }}.yml"
          exit 1
        fi
        echo "‚úÖ Archivos listos para despliegue"
    
    - name: Deploy to ${{ steps.env.outputs.env }}
      env:
        SSH_KEY: ~/.ssh/deploy_key
        SSH_HOST: ${{ secrets.SSH_HOST }}
        SSH_USER: ${{ secrets.SSH_USERNAME }}
        ENV: ${{ steps.env.outputs.env }}
      run: |
        # ENV_DIR se construye en el servidor, no en el runner
        ENV_DIR_REMOTE="~/$ENV"
        echo "üìÅ Preparando directorio $ENV_DIR_REMOTE en el servidor"
        
        # Crear directorio en el servidor
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          "mkdir -p $ENV_DIR_REMOTE/html $ENV_DIR_REMOTE/backups" || true
        
        # Preservar credentials.json si existe antes del deploy
        echo "üîê Preservando credentials.json si existe..."
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          "if [ -f '$ENV_DIR_REMOTE/html/credentials.json' ]; then
            echo 'üìã Guardando credentials.json temporalmente...'
            cp '$ENV_DIR_REMOTE/html/credentials.json' '$ENV_DIR_REMOTE/html/credentials.json.backup' || true
          fi"
        
        # Copiar c√≥digo al servidor usando rsync (excluyendo .git y otros archivos innecesarios)
        echo "üì§ Copiando c√≥digo al servidor..."
        rsync -avz --delete --no-perms --no-owner --no-group \
          -e "ssh -i $SSH_KEY -o StrictHostKeyChecking=no" \
          --exclude='.git' \
          --exclude='__pycache__' \
          --exclude='**/__pycache__' \
          --exclude='*.pyc' \
          --exclude='.env' \
          --exclude='credentials.json' \
          --exclude='venv' \
          --exclude='db.sqlite3' \
          --exclude='.pytest_cache' \
          --exclude='node_modules' \
          --exclude='.DS_Store' \
          --exclude='*.swp' \
          ./ $SSH_USER@$SSH_HOST:$ENV_DIR_REMOTE/html/ || {
            RSYNC_EXIT=$?
            if [ $RSYNC_EXIT -eq 23 ]; then
              echo "‚ö†Ô∏è  rsync complet√≥ con algunos archivos no transferidos (c√≥digo 23), continuando..."
            else
              echo "‚ùå rsync fall√≥ con c√≥digo $RSYNC_EXIT"
              exit $RSYNC_EXIT
            fi
          }
        
        # Restaurar credentials.json si exist√≠a antes
        echo "üîê Restaurando credentials.json si exist√≠a..."
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          "if [ -f '$ENV_DIR_REMOTE/html/credentials.json.backup' ]; then
            mv '$ENV_DIR_REMOTE/html/credentials.json.backup' '$ENV_DIR_REMOTE/html/credentials.json'
            echo '‚úÖ credentials.json restaurado'
          else
            echo \"‚ö†Ô∏è  credentials.json no exist√≠a antes, debe crearse manualmente en $ENV_DIR_REMOTE/html/credentials.json\"
          fi"
        
        # Copiar docker-compose al servidor (dentro de html/)
        echo "üìã Copiando docker-compose.yml a html/"
        scp -i $SSH_KEY -o StrictHostKeyChecking=no \
          docker/docker-compose.$ENV.yml \
          $SSH_USER@$SSH_HOST:$ENV_DIR_REMOTE/html/docker-compose.yml
        
        # Ejecutar despliegue en el servidor
        echo "üöÄ Ejecutando despliegue en el servidor"
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          ENV="$ENV" bash -s << 'DEPLOY_SCRIPT'
        set -e
        ENV_DIR="$HOME/$ENV"
        echo "üìÇ Cambiando a directorio: $ENV_DIR/html"
        cd $ENV_DIR/html || { echo "‚ùå Error: No se encuentra $ENV_DIR/html"; exit 1; }
        
        # Verificar que existe .env
        if [ ! -f ".env" ]; then
          echo "‚ö†Ô∏è  Advertencia: No se encuentra .env en $ENV_DIR/html/.env"
          echo "üí° El archivo .env debe existir en el servidor antes de ejecutar docker compose"
          echo "üí° Puedes crearlo manualmente o copiarlo desde $ENV_DIR/.env si existe"
          if [ -f "$ENV_DIR/.env" ]; then
            echo "üìã Copiando .env desde $ENV_DIR/.env a $ENV_DIR/html/.env"
            cp "$ENV_DIR/.env" "$ENV_DIR/html/.env"
          else
            echo "‚ùå Error: No se encuentra .env en $ENV_DIR/.env ni en $ENV_DIR/html/.env"
            echo "‚ùå El despliegue no puede continuar sin el archivo .env"
            exit 1
          fi
        else
          echo "‚úÖ Archivo .env encontrado en $ENV_DIR/html/.env"
        fi
        
        # Verificar que existe credentials.json (cr√≠tico para GCS)
        if [ ! -f "credentials.json" ]; then
          echo "‚ö†Ô∏è  Advertencia: No se encuentra credentials.json en $ENV_DIR/html/credentials.json"
          echo "üí° El archivo credentials.json debe existir en el servidor para que GCS funcione"
          echo "üí° Puedes crearlo manualmente o copiarlo desde $ENV_DIR/credentials.json si existe"
          if [ -f "$ENV_DIR/credentials.json" ]; then
            echo "üìã Copiando credentials.json desde $ENV_DIR/credentials.json a $ENV_DIR/html/credentials.json"
            cp "$ENV_DIR/credentials.json" "$ENV_DIR/html/credentials.json"
            echo "‚úÖ credentials.json copiado desde $ENV_DIR/"
          else
            echo "‚ùå Error: No se encuentra credentials.json en $ENV_DIR/credentials.json ni en $ENV_DIR/html/credentials.json"
            echo "‚ùå El despliegue puede continuar pero GCS no funcionar√° sin credentials.json"
            echo "üí° Crea el archivo manualmente en $ENV_DIR/html/credentials.json antes de usar GCS"
          fi
        else
          echo "‚úÖ Archivo credentials.json encontrado en $ENV_DIR/html/credentials.json"
        fi
        
        # Verificar que POSTGRES_PASSWORD est√° definido en .env
        echo "üîç Verificando variables cr√≠ticas en .env..."
        if grep -q "^POSTGRES_PASSWORD=" .env 2>/dev/null; then
          echo "‚úÖ POSTGRES_PASSWORD encontrado en .env"
          # Leer POSTGRES_PASSWORD del .env
          POSTGRES_PASSWORD=$(grep "^POSTGRES_PASSWORD=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'")
        else
          echo "‚ö†Ô∏è  POSTGRES_PASSWORD no est√° definido en .env"
          echo "üîë Generando contrase√±a autom√°ticamente..."
          # Generar contrase√±a segura (25 caracteres alfanum√©ricos)
          POSTGRES_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-25)
          echo "" >> .env
          echo "# PostgreSQL password (generado autom√°ticamente)" >> .env
          echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" >> .env
          echo "‚úÖ POSTGRES_PASSWORD generado y agregado al .env"
          echo "‚ö†Ô∏è  IMPORTANTE: Guarda esta contrase√±a en un lugar seguro"
          echo "üîë POSTGRES_PASSWORD=$POSTGRES_PASSWORD"
          echo "üí° Si ya existe una base de datos con otra contrase√±a, actualiza manualmente el .env"
        fi
        
        # Leer otras variables de PostgreSQL del .env o usar valores por defecto
        POSTGRES_USER=$(grep "^POSTGRES_USER=" .env 2>/dev/null | cut -d'=' -f2- | tr -d '"' | tr -d "'" || echo "atenea")
        POSTGRES_DB=$(grep "^POSTGRES_DB=" .env 2>/dev/null | cut -d'=' -f2- | tr -d '"' | tr -d "'" || echo "atenea_${ENV}")
        
        # Verificar y configurar DATABASE_URL (cr√≠tico para usar PostgreSQL, no SQLite)
        echo "üîç Verificando configuraci√≥n de DATABASE_URL..."
        if grep -q "^DATABASE_URL=" .env 2>/dev/null; then
          echo "‚úÖ DATABASE_URL encontrado en .env"
          DATABASE_URL=$(grep "^DATABASE_URL=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'")
          # Verificar que DATABASE_URL apunta a PostgreSQL
          if [[ ! "$DATABASE_URL" == postgresql://* ]]; then
            echo "‚ö†Ô∏è  Advertencia: DATABASE_URL no apunta a PostgreSQL, actualizando..."
            DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
            # Actualizar DATABASE_URL en .env
            sed -i "s|^DATABASE_URL=.*|DATABASE_URL=${DATABASE_URL}|" .env || echo "DATABASE_URL=${DATABASE_URL}" >> .env
            echo "‚úÖ DATABASE_URL actualizado a PostgreSQL"
          fi
        else
          echo "‚ö†Ô∏è  DATABASE_URL no est√° definido en .env"
          echo "üîß Configurando DATABASE_URL autom√°ticamente..."
          DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
          echo "" >> .env
          echo "# Database URL (configurado autom√°ticamente)" >> .env
          echo "DATABASE_URL=${DATABASE_URL}" >> .env
          echo "‚úÖ DATABASE_URL configurado: postgresql://${POSTGRES_USER}:***@db:5432/${POSTGRES_DB}"
        fi
        
        # Asegurar que USE_SQLITE=False en todos los entornos (todos usan PostgreSQL)
        echo "üîç Verificando USE_SQLITE para entorno $ENV..."
        if grep -q "^USE_SQLITE=" .env 2>/dev/null; then
          USE_SQLITE_VALUE=$(grep "^USE_SQLITE=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'" | tr '[:upper:]' '[:lower:]')
          if [ "$USE_SQLITE_VALUE" == "true" ]; then
            echo "‚ö†Ô∏è  USE_SQLITE=True detectado en entorno $ENV, cambiando a False..."
            sed -i "s|^USE_SQLITE=.*|USE_SQLITE=False|" .env
            echo "‚úÖ USE_SQLITE actualizado a False"
          else
            echo "‚úÖ USE_SQLITE ya est√° en False"
          fi
        else
          echo "üîß Agregando USE_SQLITE=False al .env"
          echo "" >> .env
          echo "# Use PostgreSQL in all environments" >> .env
          echo "USE_SQLITE=False" >> .env
          echo "‚úÖ USE_SQLITE=False agregado al .env"
        fi
        
        # Mostrar informaci√≥n del .env (sin mostrar valores sensibles)
        echo "üìã Variables definidas en .env (primeras 10):"
        grep -E "^[A-Z_]+=" .env | sed 's/=.*/=***/' | head -10 || echo "‚ö†Ô∏è  No se pudieron leer las variables del .env"
        
        echo "üõë Deteniendo y eliminando contenedores existentes"
        
        # Funci√≥n para eliminar contenedores de forma agresiva
        cleanup_containers() {
          local pattern=$1
          echo "üîç Buscando contenedores con patr√≥n: $pattern"
          local containers=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^${pattern}" || echo "")
          if [ ! -z "$containers" ]; then
            echo "$containers" | while IFS= read -r container; do
              if [ ! -z "$container" ]; then
                echo "üõë Deteniendo contenedor: $container"
                docker stop "$container" 2>/dev/null || true
                echo "üóëÔ∏è  Eliminando contenedor: $container"
                docker rm -f "$container" 2>/dev/null || true
              fi
            done
          fi
        }
        
        # Establecer nombre de proyecto √∫nico para evitar conflictos
        export COMPOSE_PROJECT_NAME="html-${ENV}"
        
        # Paso 1: Detener y eliminar usando docker compose (si estamos en el directorio correcto)
        echo "‚è∏Ô∏è  Deteniendo contenedores con docker compose (proyecto: html-${ENV})..."
        docker compose stop 2>/dev/null || true
        docker compose down --remove-orphans 2>/dev/null || true
        docker compose rm -f 2>/dev/null || true
        
        # Paso 2: Eliminar TODOS los contenedores que empiecen con "html-" (m√°s agresivo)
        echo "üîç Eliminando todos los contenedores con prefijo 'html-'..."
        cleanup_containers "html-"
        
        # Paso 3: Eliminar contenedores espec√≠ficos del entorno actual
        echo "üîç Eliminando contenedores del entorno ${ENV}..."
        cleanup_containers "${ENV}-"
        
        # Paso 4: Eliminar contenedores espec√≠ficos comunes por nombre exacto
        echo "üîç Eliminando contenedores espec√≠ficos conocidos..."
        COMMON_CONTAINERS=(
          "html-web-1" "html-db-1" "html-redis-1" "html-celery_worker-1" "html-celery_beat-1"
          "html-migrate-1" "html-collectstatic-1"
          "html-dev-web-1" "html-dev-db-1" "html-dev-redis-1" "html-dev-celery_worker-1" "html-dev-celery_beat-1"
          "html-demo-web-1" "html-demo-db-1" "html-demo-redis-1"
          "html-prod-web-1" "html-prod-db-1" "html-prod-redis-1"
        )
        
        for container in "${COMMON_CONTAINERS[@]}"; do
          if docker ps -a --format "{{.Names}}" 2>/dev/null | grep -q "^${container}$"; then
            echo "üõë Forzando eliminaci√≥n de: $container"
            docker stop "$container" 2>/dev/null || true
            docker rm -f "$container" 2>/dev/null || true
          fi
        done
        
        # Esperar un momento para que Docker procese las eliminaciones
        sleep 3
        
        # Paso 5: Limpiar redes hu√©rfanas
        echo "üßπ Limpiando redes hu√©rfanas..."
        docker network prune -f 2>/dev/null || true
        
        # Paso 6: Verificar y eliminar cualquier contenedor restante que pueda causar conflictos
        echo "üîç Verificaci√≥n final: buscando contenedores restantes..."
        REMAINING=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^(html-|${ENV}-)" || echo "")
        if [ ! -z "$REMAINING" ]; then
          echo "‚ö†Ô∏è  A√∫n quedan contenedores, eliminando forzadamente:"
          echo "$REMAINING"
          echo "$REMAINING" | while IFS= read -r container; do
            if [ ! -z "$container" ]; then
              echo "üóëÔ∏è  Eliminando forzadamente: $container"
              docker stop "$container" 2>/dev/null || true
              docker rm -f "$container" 2>/dev/null || true
            fi
          done
          sleep 2
        else
          echo "  ‚úÖ Todos los contenedores conflictivos eliminados"
        fi
        
        # Verificaci√≥n final
        FINAL_CHECK=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^(html-|${ENV}-)" || echo "")
        if [ ! -z "$FINAL_CHECK" ]; then
          echo "‚ö†Ô∏è  Advertencia: Algunos contenedores a√∫n existen pero continuando..."
          echo "$FINAL_CHECK"
        fi
        echo "üî® Construyendo y reiniciando contenedores"
        # Establecer nombre de proyecto √∫nico para evitar conflictos
        export COMPOSE_PROJECT_NAME="html-${ENV}"
        docker compose build --no-cache
        docker compose up -d
        echo "‚è≥ Esperando a que los servicios est√©n listos..."
        sleep 15
        
        # Verificar que la base de datos est√© accesible antes de ejecutar migraciones
        echo "üîç Verificando conexi√≥n a la base de datos..."
        MAX_RETRIES=10
        RETRY_COUNT=0
        while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
          if docker compose exec -T db pg_isready -U "${POSTGRES_USER}" > /dev/null 2>&1; then
            echo "‚úÖ Base de datos accesible"
            break
          else
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "‚è≥ Esperando a que la base de datos est√© lista... (intento $RETRY_COUNT/$MAX_RETRIES)"
            sleep 3
          fi
        done
        
        if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
          echo "‚ùå Error: No se puede conectar a la base de datos despu√©s de $MAX_RETRIES intentos"
          exit 1
        fi
        
        # Verificar que la base de datos existe, si no, crearla
        echo "üîç Verificando que la base de datos existe..."
        DB_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -lqt 2>/dev/null | cut -d \| -f 1 | grep -w "${POSTGRES_DB}" | wc -l || echo "0")
        if [ "$DB_EXISTS" == "0" ]; then
          echo "‚ö†Ô∏è  La base de datos ${POSTGRES_DB} no existe, cre√°ndola..."
          docker compose exec -T db psql -U "${POSTGRES_USER}" -c "CREATE DATABASE ${POSTGRES_DB};" postgres || {
            echo "‚ùå Error al crear la base de datos"
            exit 1
          }
          echo "‚úÖ Base de datos ${POSTGRES_DB} creada"
        else
          echo "‚úÖ Base de datos ${POSTGRES_DB} existe"
        fi
        
        # Asegurar que COMPOSE_PROJECT_NAME est√© configurado para las operaciones siguientes
        export COMPOSE_PROJECT_NAME="html-${ENV}"
        
        # ============================================
        # LIMPIEZA Y NORMALIZACI√ìN DE MIGRACIONES
        # ============================================
        echo "üîç Verificando estado de migraciones de core..."
        
        # Verificar si existe la tabla django_migrations
        TABLE_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name='django_migrations');" 2>/dev/null | tr -d '[:space:]' || echo "f")
        
        if [ "$TABLE_EXISTS" == "t" ]; then
          # Detectar estado actual
          HAS_0001_INITIAL=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT COUNT(*) FROM django_migrations WHERE app='core' AND name='0001_initial';" 2>/dev/null | tr -d '[:space:]' || echo "0")
          HAS_SQUASHED=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT COUNT(*) FROM django_migrations WHERE app='core' AND name LIKE '0001_initial_squashed%';" 2>/dev/null | tr -d '[:space:]' || echo "0")
          HAS_0030=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT COUNT(*) FROM django_migrations WHERE app='core' AND name='0030_remove_unique_from_task_id';" 2>/dev/null | tr -d '[:space:]' || echo "0")
          
          echo "  Migraci√≥n 0001_initial individual: $HAS_0001_INITIAL"
          echo "  Migraci√≥n squashed: $HAS_SQUASHED"
          echo "  Migraci√≥n 0030 individual: $HAS_0030"
          
          # Caso 1: Solo migraciones individuales (sin squashed)
          if [ "$HAS_0001_INITIAL" -gt 0 ] && [ "$HAS_SQUASHED" -eq 0 ]; then
            echo "‚ö†Ô∏è  Detectado: Migraciones individuales sin squashed"
            echo "üîß Aplicando migraci√≥n squashed con --fake (tablas ya existen)..."
            if docker compose run --rm web python manage.py migrate core 0001_initial_squashed_0030_remove_unique_from_task_id --fake; then
              echo "‚úÖ Migraci√≥n squashed marcada como aplicada"
            else
              echo "‚ö†Ô∏è  Advertencia: No se pudo aplicar squashed con --fake (continuando...)"
            fi
          fi
          
          # Caso 2: Estado mixto (individuales + squashed)
          if [ "$HAS_0001_INITIAL" -gt 0 ] && [ "$HAS_SQUASHED" -gt 0 ]; then
            echo "‚ö†Ô∏è  Detectado: Estado mixto (migraciones individuales + squashed)"
            echo "üîß Limpiando migraciones individuales duplicadas (0001-0030)..."
            
            docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -c "
            DELETE FROM django_migrations 
            WHERE app='core' 
            AND name IN (
                '0001_initial',
                '0002_alter_video_type',
                '0003_image',
                '0004_alter_video_type',
                '0005_script',
                '0006_script_desired_duration_min',
                '0007_script_agent_flow_script_final_video_scene',
                '0008_script_video_config',
                '0009_scene_image_source_freepik',
                '0010_update_heygen_services',
                '0011_scene_audio_duration_scene_audio_error_message_and_more',
                '0012_scene_visual_prompt_alter_scene_script_text',
                '0013_music',
                '0014_add_project_sharing',
                '0015_assign_project_owners',
                '0016_alter_audio_project_alter_image_project_and_more',
                '0017_audio_created_by_image_created_by_music_created_by_and_more',
                '0018_usercredits_credittransaction_serviceusage',
                '0019_add_permission_groups',
                '0020_increase_video_type_max_length',
                '0021_alter_scene_ai_service',
                '0022_add_generation_task',
                '0023_add_notification',
                '0024_rename_core_genera_user_id_idx_generation__user_id_7f7fbf_idx_and_more',
                '0025_fix_generation_task_task_id_nullable',
                '0026_add_uuid_to_video_image_audio',
                '0027_add_uuid_to_project',
                '0028_unify_audio_music',
                '0029_unify_audio_music',
                '0030_remove_unique_from_task_id'
            )
            AND name NOT LIKE '%squashed%';
            " 2>/dev/null && echo "‚úÖ Migraciones individuales duplicadas eliminadas" || echo "‚ö†Ô∏è  Advertencia: No se pudieron eliminar migraciones duplicadas (continuando...)"
          fi
          
          # Caso 3: Instalaci√≥n nueva (sin migraciones)
          if [ "$HAS_0001_INITIAL" -eq 0 ] && [ "$HAS_SQUASHED" -eq 0 ]; then
            echo "‚úÖ Instalaci√≥n nueva detectada - se aplicar√°n migraciones normalmente"
          fi
          
          echo "‚úÖ Estado de migraciones verificado y normalizado"
        else
          echo "‚ÑπÔ∏è  Tabla django_migrations no existe - instalaci√≥n nueva"
        fi
        
        echo "üîÑ Ejecutando migraciones"
        echo "üìã Verificando migraciones pendientes..."
        MIGRATION_OUTPUT=$(docker compose run --rm migrate 2>&1)
        MIGRATION_EXIT_CODE=$?
        
        echo "$MIGRATION_OUTPUT"
        
        if [ $MIGRATION_EXIT_CODE -eq 0 ]; then
          echo "‚úÖ Migraciones ejecutadas correctamente"
        else
          echo "‚ùå Error: Las migraciones fallaron con c√≥digo $MIGRATION_EXIT_CODE"
          echo "üîç Verificando estado de la base de datos..."
          docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -c "\dt" || true
          echo "üîÑ Intentando ejecutar migraciones nuevamente..."
          sleep 5
          if docker compose run --rm migrate; then
            echo "‚úÖ Migraciones ejecutadas correctamente en el segundo intento"
          else
            echo "‚ùå Error: Las migraciones fallaron nuevamente"
            exit 1
          fi
        fi
        
        # Verificar que las tablas principales de Django existen
        echo "üîç Verificando que las tablas principales existen..."
        REQUIRED_TABLES=("django_migrations" "django_session" "auth_user" "core_project")
        MISSING_TABLES=()
        
        for table in "${REQUIRED_TABLES[@]}"; do
          TABLE_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name='${table}');" 2>/dev/null | tr -d '[:space:]' || echo "f")
          if [ "$TABLE_EXISTS" != "t" ]; then
            MISSING_TABLES+=("$table")
          fi
        done
        
        if [ ${#MISSING_TABLES[@]} -gt 0 ]; then
          echo "‚ö†Ô∏è  Advertencia: Faltan las siguientes tablas: ${MISSING_TABLES[*]}"
          echo "üîÑ Ejecutando migraciones nuevamente para crear las tablas faltantes..."
          sleep 5
          if docker compose run --rm migrate; then
            echo "‚úÖ Migraciones ejecutadas nuevamente"
            # Verificar nuevamente
            for table in "${MISSING_TABLES[@]}"; do
              TABLE_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name='${table}');" 2>/dev/null | tr -d '[:space:]' || echo "f")
              if [ "$TABLE_EXISTS" == "t" ]; then
                echo "‚úÖ Tabla ${table} creada correctamente"
              else
                echo "‚ùå Error: La tabla ${table} a√∫n no existe despu√©s de las migraciones"
                exit 1
              fi
            done
          else
            echo "‚ùå Error: No se pudieron crear las tablas faltantes"
            echo "üìã Estado actual de la base de datos:"
            docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -c "\dt" || true
            exit 1
          fi
        else
          echo "‚úÖ Todas las tablas principales existen"
        fi
        
        echo "üì¶ Recolectando archivos est√°ticos"
        if docker compose run --rm collectstatic; then
          echo "‚úÖ Archivos est√°ticos recolectados correctamente"
        else
          echo "‚ö†Ô∏è  Advertencia: Error en collectstatic (no cr√≠tico, continuando...)"
        fi
        echo "‚úÖ Despliegue a $ENV completado!"
        if [ "$ENV" == "prod" ]; then
          echo "üåê URL: https://atenea.nxhumans.com"
        else
          echo "üåê URL: https://$ENV.atenea.nxhumans.com"
        fi
        DEPLOY_SCRIPT
