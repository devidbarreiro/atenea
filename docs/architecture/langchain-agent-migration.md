# ğŸš€ MigraciÃ³n a Agente LangChain: DocumentaciÃ³n Ejecutiva

## ğŸ“‹ Resumen Ejecutivo

**Objetivo:** Reemplazar la dependencia externa de n8n con un agente propio basado en LangChain, mejorando control, velocidad y observabilidad del proceso de anÃ¡lisis de guiones.

**Beneficios Clave:**
- âœ… **EliminaciÃ³n de dependencia externa** (n8n)
- âœ… **ReducciÃ³n de latencia** (~70% mÃ¡s rÃ¡pido)
- âœ… **Control total** sobre el proceso de anÃ¡lisis
- âœ… **Observabilidad completa** (tokens, costos, latencia)
- âœ… **ValidaciÃ³n automÃ¡tica** y correcciÃ³n de errores
- âœ… **CachÃ© inteligente** para reducir costos

---

## ğŸ”„ LangGraph vs Chain Simple: Â¿CuÃ¡l Elegir?

### **Chain Simple (LCEL)**
**QuÃ© es:** Un flujo lineal donde el prompt se envÃ­a directamente al LLM y se procesa la respuesta.

**Ventajas:**
- âœ… MÃ¡s simple de implementar
- âœ… Menos overhead
- âœ… Ideal para tareas simples y directas

**Desventajas:**
- âŒ No permite pasos intermedios
- âŒ DifÃ­cil de debuggear
- âŒ No permite validaciÃ³n antes de finalizar
- âŒ No permite retry inteligente

**Ejemplo:**
```
Prompt â†’ LLM â†’ Respuesta JSON â†’ Validar â†’ Listo
```

### **LangGraph (Recomendado)**
**QuÃ© es:** Un grafo de estado que permite mÃºltiples pasos, validaciones intermedias, y flujos condicionales.

**Ventajas:**
- âœ… **Pasos intermedios:** Puedes validar antes de continuar
- âœ… **Retry inteligente:** Si falla validaciÃ³n, reintenta solo esa parte
- âœ… **Observabilidad:** Trackeas cada paso individualmente
- âœ… **CorrecciÃ³n automÃ¡tica:** Si detecta error, puede corregirlo
- âœ… **Escalable:** FÃ¡cil agregar nuevos pasos

**Desventajas:**
- âŒ MÃ¡s complejo inicialmente
- âŒ MÃ¡s overhead (mÃ­nimo)

**Ejemplo:**
```
[Start] â†’ [Analizar GuiÃ³n] â†’ [Generar Escenas] â†’ [Validar DuraciÃ³n] 
    â†“                              â†“                    â†“
[Log]                          [Log]                [Si invÃ¡lido â†’ Corregir]
    â†“                              â†“                    â†“
[Continuar] â†’ [Validar JSON] â†’ [Formatear] â†’ [End]
```

### **RecomendaciÃ³n: LangGraph** âœ…

**Razones:**
1. **ValidaciÃ³n crÃ­tica:** Necesitamos validar duraciones por plataforma (Sora: 4/8/12s, Veo: â‰¤8s, HeyGen: 30-60s)
2. **CorrecciÃ³n automÃ¡tica:** Si el LLM genera duraciÃ³n invÃ¡lida, podemos corregirla automÃ¡ticamente
3. **Observabilidad:** Necesitamos trackear cada paso para debugging y optimizaciÃ³n
4. **Escalabilidad futura:** FÃ¡cil agregar nuevas validaciones o pasos

---

## ğŸ—ï¸ Arquitectura Propuesta

### Flujo LangGraph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   START     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Analyze Script  â”‚ â† Analiza guiÃ³n y duraciÃ³n
â”‚ (LLM Call)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generate Scenes â”‚ â† Genera escenas con LLM
â”‚ (LLM Call)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Validate Output â”‚ â† Valida duraciones, formato
â”‚ (Tools)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â†’ [VÃ¡lido] â”€â”€â”
       â”‚              â”‚
       â””â”€â†’ [InvÃ¡lido] â”€â”€â†’ [Auto-Correct] â”€â”€â”
                                            â”‚
                                            â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Format JSON  â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚     END      â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **Script Agent (LangGraph)**
   - Nodos: Analyze, Generate, Validate, Correct, Format
   - Estado: Script text, scenes, validation errors

2. **Tools (Herramientas)**
   - `DurationValidator`: Valida duraciones por plataforma
   - `WordCounter`: Cuenta palabras vs duraciÃ³n
   - `JSONValidator`: Valida estructura JSON
   - `PlatformSelector`: Sugiere plataforma Ã³ptima
   - `AutoCorrector`: Corrige errores comunes

3. **LLM Factory**
   - Soporte para OpenAI (GPT-4) y Gemini Pro
   - Fallback automÃ¡tico
   - Rate limiting

4. **Observabilidad**
   - LangSmith: Trazabilidad completa
   - Django Logging: Logs estructurados
   - MÃ©tricas: Tokens, latencia, costos

5. **CachÃ©**
   - Redis: CachÃ© por hash del guiÃ³n
   - TTL: 24 horas
   - InvalidaciÃ³n inteligente

---

## ğŸ“Š Comparativa: Antes vs DespuÃ©s

| Aspecto | n8n (Actual) | LangChain (Nuevo) |
|---------|--------------|-------------------|
| **Latencia** | ~30-60s (HTTP + procesamiento) | ~10-20s (procesamiento directo) |
| **Dependencias** | Externa (n8n server) | Interna (solo cÃ³digo) |
| **Control** | Limitado (solo webhook) | Total (cÃ³digo propio) |
| **Observabilidad** | Solo logs de n8n | LangSmith + Django logs |
| **ValidaciÃ³n** | Manual (post-procesamiento) | AutomÃ¡tica (durante generaciÃ³n) |
| **CorrecciÃ³n** | Manual | AutomÃ¡tica |
| **CachÃ©** | No | SÃ­ (Redis) |
| **Costos** | No trackeable | Trackeable por request |
| **Debugging** | DifÃ­cil | FÃ¡cil (trazabilidad completa) |

---

## ğŸ’° AnÃ¡lisis de Costos

### EstimaciÃ³n Mensual (1000 guiones/mes)

**n8n (Actual):**
- Costo n8n: $0 (self-hosted) o ~$20/mes (cloud)
- Sin tracking de costos LLM

**LangChain (Nuevo):**
- OpenAI GPT-4: ~$0.03 por guiÃ³n = **$30/mes**
- Gemini Pro: ~$0.01 por guiÃ³n = **$10/mes**
- Con cachÃ© (30% hit rate): **$21-28/mes**

**Ahorro con cachÃ©:** ~30% de reducciÃ³n en costos LLM

---

## ğŸ”§ Herramientas de ValidaciÃ³n

### 1. **DurationValidator**
Valida que las duraciones sean vÃ¡lidas segÃºn plataforma:
- Sora: Exactamente 4, 8, o 12 segundos
- Gemini Veo: Entre 5 y 8 segundos
- HeyGen: Entre 30 y 60 segundos

### 2. **WordCounter**
Valida que el texto tenga palabras apropiadas para la duraciÃ³n:
- 5s: 10-11 palabras
- 8s: 16-18 palabras
- 12s: 22-25 palabras

### 3. **JSONValidator**
Valida estructura JSON completa:
- Campos requeridos presentes
- Tipos correctos
- Valores vÃ¡lidos

### 4. **PlatformSelector**
Sugiere plataforma Ã³ptima basado en:
- Tipo de contenido (presentador vs b-roll)
- DuraciÃ³n requerida
- Estilo visual

### 5. **AutoCorrector**
Corrige errores comunes:
- Duraciones invÃ¡lidas â†’ Ajusta al valor mÃ¡s cercano vÃ¡lido
- Campos faltantes â†’ Genera valores por defecto
- Formato incorrecto â†’ Reformatea

---

## ğŸ“ˆ Observabilidad

### LangSmith
- **Trazabilidad completa:** Cada llamada al LLM trackeada
- **VisualizaciÃ³n:** Ver el flujo completo en tiempo real
- **Debugging:** Inspeccionar prompts y respuestas
- **Costos:** Tracking automÃ¡tico de tokens y costos

### Django Logging
- **Logs estructurados:** JSON logs para fÃ¡cil parsing
- **Niveles:** DEBUG, INFO, WARNING, ERROR
- **Contexto:** Script ID, usuario, duraciÃ³n, etc.

### MÃ©tricas Personalizadas
- Tokens usados (input/output)
- Latencia por paso
- Costos por request
- Tasa de Ã©xito/error
- Tasa de cachÃ© hit

---

## ğŸ’¾ Estrategia de CachÃ©

### CÃ³mo Funciona

1. **Hash del guiÃ³n:** Genera hash SHA256 del texto del guiÃ³n + duraciÃ³n
2. **Check Redis:** Si existe en cachÃ©, retorna inmediatamente
3. **Si no existe:** Procesa con LLM y guarda en cachÃ©
4. **TTL:** 24 horas (configurable)

### Beneficios

- **ReducciÃ³n de costos:** ~30% menos llamadas al LLM
- **Velocidad:** Respuesta instantÃ¡nea para guiones repetidos
- **Escalabilidad:** Maneja mejor picos de trÃ¡fico

### InvalidaciÃ³n

- Manual: Por admin
- AutomÃ¡tica: DespuÃ©s de TTL
- Por versiÃ³n: Si cambia el prompt, invalida cachÃ©

---

## ğŸš¦ Rate Limiting

### Estrategia Inicial

**Por usuario:**
- 10 guiones/hora
- 50 guiones/dÃ­a

**Por proyecto:**
- 5 guiones/hora
- 20 guiones/dÃ­a

**Global:**
- 100 guiones/hora
- 1000 guiones/dÃ­a

### Ajuste DinÃ¡mico

Monitorear durante 2 semanas y ajustar segÃºn:
- Uso real
- Costos LLM
- Latencia del sistema

---

## ğŸ§ª Testing y Desarrollo

### Modo Desarrollo

1. **Mock Responses:** Respuestas predefinidas sin llamar al LLM
2. **Dry Run:** Valida flujo sin generar escenas reales
3. **Test Fixtures:** Guiones de prueba con resultados esperados

### Testing

- **Unit Tests:** Cada herramienta individualmente
- **Integration Tests:** Flujo completo end-to-end
- **E2E Tests:** Con guiones reales

---

## ğŸ“ Versionado de Prompts

### Estructura

```
config/prompts/
â”œâ”€â”€ script_analysis/
â”‚   â”œâ”€â”€ v1.yaml
â”‚   â”œâ”€â”€ v2.yaml (actual)
â”‚   â””â”€â”€ v3.yaml (experimental)
â””â”€â”€ scene_generation/
    â”œâ”€â”€ v1.yaml
    â””â”€â”€ v2.yaml
```

### A/B Testing

- **50% usuarios:** Prompt v2
- **50% usuarios:** Prompt v3
- **MÃ©tricas:** Comparar calidad de escenas generadas
- **DecisiÃ³n:** Elegir mejor prompt despuÃ©s de 1 semana

---

## ğŸ“… Plan de ImplementaciÃ³n

### Fase 1: Setup (Semana 1)
- [ ] Instalar dependencias (LangChain, LangSmith)
- [ ] Configurar LangSmith
- [ ] Crear estructura de archivos
- [ ] Setup bÃ¡sico de LLM Factory

### Fase 2: Agente Base (Semana 2)
- [ ] Implementar LangGraph bÃ¡sico
- [ ] Crear herramientas de validaciÃ³n
- [ ] Integrar con servicios existentes
- [ ] Tests bÃ¡sicos

### Fase 3: Observabilidad (Semana 3)
- [ ] Configurar LangSmith
- [ ] Implementar mÃ©tricas
- [ ] Dashboard de monitoreo
- [ ] Alertas

### Fase 4: OptimizaciÃ³n (Semana 4)
- [ ] Implementar cachÃ©
- [ ] Rate limiting
- [ ] Auto-correcciÃ³n
- [ ] Performance tuning

### Fase 5: MigraciÃ³n (Semana 5)
- [ ] Feature flag para alternar n8n/LangChain
- [ ] Testing en producciÃ³n (10% trÃ¡fico)
- [ ] Monitoreo intensivo
- [ ] MigraciÃ³n completa

---

## ğŸ¯ MÃ©tricas de Ã‰xito

### TÃ©cnicas
- âœ… Latencia < 20s (vs 30-60s actual)
- âœ… Tasa de Ã©xito > 95%
- âœ… ValidaciÃ³n automÃ¡tica 100%
- âœ… CachÃ© hit rate > 30%

### Negocio
- âœ… ReducciÃ³n de costos operativos (sin n8n)
- âœ… Mejor control sobre calidad
- âœ… Escalabilidad mejorada
- âœ… Mejor experiencia de usuario

---

## ğŸ“š Referencias

- [LangChain Documentation](https://python.langchain.com/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangSmith Documentation](https://docs.smith.langchain.com/)

---

**Fecha:** Enero 2025  
**VersiÃ³n:** 1.0  
**Autor:** Equipo de Desarrollo Atenea

