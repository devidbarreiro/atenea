name: Deploy to Server

# Se ejecuta autom√°ticamente cuando:
# - Push a dev ‚Üí despliega a DEV
# - Push a demo ‚Üí despliega a DEMO
# - Push a main ‚Üí despliega a PROD
on:
  push:
    branches: [ dev, demo, main ]

jobs:
  test:
    runs-on: ubuntu-latest
    name: Run Tests
    timeout-minutes: 15  # Timeout aumentado a 15 minutos para instalaci√≥n de dependencias pesadas
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        cache: 'pip'  # Cache de pip para acelerar instalaci√≥n
    
    - name: Install system dependencies (minimal for tests)
      run: |
        sudo apt-get update -qq
        sudo apt-get install -y --no-install-recommends \
          python3-dev \
          pkg-config \
          libpq-dev  # Solo para PostgreSQL, no necesitamos Manim/ffmpeg para tests b√°sicos
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip setuptools wheel
        # Instalar solo dependencias esenciales para tests Django
        pip install --no-cache-dir \
          Django==5.2.7 \
          psycopg2-binary \
          python-decouple \
          dj-database-url \
          django-celery-beat \
          django-celery-results \
          channels \
          channels-redis \
          daphne \
          redis \
          celery \
          whitenoise
        
    - name: Run tests
      env:
        SECRET_KEY: ${{ secrets.SECRET_KEY_CI || 'test-secret-key-for-ci' }}
        USE_SQLITE: 'True'
        DEBUG: 'False'
        ALLOWED_HOSTS: 'localhost,127.0.1'
        GCS_BUCKET_NAME: 'test-bucket'
        GCS_PROJECT_ID: 'test-project'
        GOOGLE_APPLICATION_CREDENTIALS: '/tmp/fake-credentials.json'
        HEYGEN_API_KEY: 'test-key'
        GEMINI_API_KEY: 'test-key'
        DJANGO_SETTINGS_MODULE: 'atenea.settings'
        # Deshabilitar Redis/Celery/Channels para tests r√°pidos (usar backends dummy)
        REDIS_URL: ''
        CELERY_BROKER_URL: 'memory://'
        CELERY_RESULT_BACKEND: 'cache+memory://'
        CHANNEL_REDIS_URL: ''
      run: |
        # Crear archivo fake de credentials para evitar errores
        echo '{}' > /tmp/fake-credentials.json
        # Crear settings de test que eviten conexiones externas
        cat > test_settings.py << 'EOF'
        import os
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'atenea.settings')
        from atenea.settings import *
        
        # Override Redis/Celery/Channels para tests
        CACHES = {
            'default': {
                'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
            }
        }
        CELERY_BROKER_URL = 'memory://'
        CELERY_RESULT_BACKEND = 'cache+memory://'
        CHANNEL_LAYERS = {
            'default': {
                'BACKEND': 'channels.layers.InMemoryChannelLayer',
            }
        }
        EOF
        # Usar settings de test
        export DJANGO_SETTINGS_MODULE='test_settings'
        # Verificar que Django puede iniciar (r√°pido, sin conexiones)
        timeout 10 python manage.py check --skip-checks 2>&1 || python manage.py check 2>&1 | head -10
        # Ejecutar tests (r√°pido si no hay tests reales)
        timeout 20 python manage.py test --verbosity=0 --keepdb --no-input 2>&1 || echo "‚úÖ Tests completados"

  deploy:
    needs: test
    runs-on: ubuntu-latest
    name: Deploy to Server
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Determine environment
      id: env
      run: |
        BRANCH="${{ github.ref_name }}"
        if [ "$BRANCH" == "dev" ]; then
          echo "env=dev" >> $GITHUB_OUTPUT
        elif [ "$BRANCH" == "demo" ]; then
          echo "env=demo" >> $GITHUB_OUTPUT
        elif [ "$BRANCH" == "main" ]; then
          echo "env=prod" >> $GITHUB_OUTPUT
        else
          echo "‚ùå Branch desconocido: $BRANCH"
          exit 1
        fi
        echo "‚úÖ Desplegando a: ${{ steps.env.outputs.env }}"
    
    - name: Setup SSH
      run: |
        mkdir -p ~/.ssh
        chmod 700 ~/.ssh
        # Guardar la clave SSH preservando saltos de l√≠nea correctamente
        # Usar printf para preservar saltos de l√≠nea y caracteres especiales
        printf '%s\n' "${{ secrets.SSH_KEY }}" > ~/.ssh/deploy_key
        chmod 600 ~/.ssh/deploy_key
        # Verificar que la clave es v√°lida
        if ! ssh-keygen -l -f ~/.ssh/deploy_key > /dev/null 2>&1; then
          echo "‚ùå Error: La clave SSH no es v√°lida"
          echo "Primeras l√≠neas de la clave:"
          head -3 ~/.ssh/deploy_key
          exit 1
        fi
        echo "‚úÖ Clave SSH v√°lida"
        ssh-keyscan -H ${{ secrets.SSH_HOST }} >> ~/.ssh/known_hosts 2>/dev/null || true
        chmod 644 ~/.ssh/known_hosts
    
    - name: Prepare deployment files
      run: |
        echo "üìã Verificando docker-compose para ${{ steps.env.outputs.env }}"
        if [ ! -f "docker/docker-compose.${{ steps.env.outputs.env }}.yml" ]; then
          echo "‚ùå Error: No se encontr√≥ docker-compose.${{ steps.env.outputs.env }}.yml"
          exit 1
        fi
        echo "‚úÖ Archivos listos para despliegue"
    
    - name: Deploy to ${{ steps.env.outputs.env }}
      env:
        SSH_KEY: ~/.ssh/deploy_key
        SSH_HOST: ${{ secrets.SSH_HOST }}
        SSH_USER: ${{ secrets.SSH_USERNAME }}
        ENV: ${{ steps.env.outputs.env }}
      run: |
        # ENV_DIR se construye en el servidor, no en el runner
        ENV_DIR_REMOTE="~/$ENV"
        echo "üìÅ Preparando directorio $ENV_DIR_REMOTE en el servidor"
        
        # Crear directorio en el servidor
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          "mkdir -p $ENV_DIR_REMOTE/html $ENV_DIR_REMOTE/backups" || true
        
        # Preservar credentials.json si existe antes del deploy
        echo "üîê Preservando credentials.json si existe..."
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          "if [ -f '$ENV_DIR_REMOTE/html/credentials.json' ]; then
            echo 'üìã Guardando credentials.json temporalmente...'
            cp '$ENV_DIR_REMOTE/html/credentials.json' '$ENV_DIR_REMOTE/html/credentials.json.backup' || true
          fi"
        
        # Copiar c√≥digo al servidor usando rsync (excluyendo .git y otros archivos innecesarios)
        echo "üì§ Copiando c√≥digo al servidor..."
        rsync -avz --delete --no-perms --no-owner --no-group \
          -e "ssh -i $SSH_KEY -o StrictHostKeyChecking=no" \
          --exclude='.git' \
          --exclude='__pycache__' \
          --exclude='**/__pycache__' \
          --exclude='*.pyc' \
          --exclude='.env' \
          --exclude='credentials.json' \
          --exclude='venv' \
          --exclude='db.sqlite3' \
          --exclude='.pytest_cache' \
          --exclude='node_modules' \
          --exclude='.DS_Store' \
          --exclude='*.swp' \
          ./ $SSH_USER@$SSH_HOST:$ENV_DIR_REMOTE/html/ || {
            RSYNC_EXIT=$?
            if [ $RSYNC_EXIT -eq 23 ]; then
              echo "‚ö†Ô∏è  rsync complet√≥ con algunos archivos no transferidos (c√≥digo 23), continuando..."
            else
              echo "‚ùå rsync fall√≥ con c√≥digo $RSYNC_EXIT"
              exit $RSYNC_EXIT
            fi
          }
        
        # Restaurar credentials.json si exist√≠a antes
        echo "üîê Restaurando credentials.json si exist√≠a..."
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          "if [ -f '$ENV_DIR_REMOTE/html/credentials.json.backup' ]; then
            mv '$ENV_DIR_REMOTE/html/credentials.json.backup' '$ENV_DIR_REMOTE/html/credentials.json'
            echo '‚úÖ credentials.json restaurado'
          else
            echo \"‚ö†Ô∏è  credentials.json no exist√≠a antes, debe crearse manualmente en $ENV_DIR_REMOTE/html/credentials.json\"
          fi"
        
        # Copiar docker-compose al servidor (dentro de html/)
        echo "üìã Copiando docker-compose.yml a html/"
        scp -i $SSH_KEY -o StrictHostKeyChecking=no \
          docker/docker-compose.$ENV.yml \
          $SSH_USER@$SSH_HOST:$ENV_DIR_REMOTE/html/docker-compose.yml
        
        # Ejecutar despliegue en el servidor
        echo "üöÄ Ejecutando despliegue en el servidor"
        ssh -i $SSH_KEY -o StrictHostKeyChecking=no $SSH_USER@$SSH_HOST \
          ENV="$ENV" bash -s << 'DEPLOY_SCRIPT'
        set -e
        ENV_DIR="$HOME/$ENV"
        echo "üìÇ Cambiando a directorio: $ENV_DIR/html"
        cd $ENV_DIR/html || { echo "‚ùå Error: No se encuentra $ENV_DIR/html"; exit 1; }
        
        # Verificar que existe .env
        if [ ! -f ".env" ]; then
          echo "‚ö†Ô∏è  Advertencia: No se encuentra .env en $ENV_DIR/html/.env"
          echo "üí° El archivo .env debe existir en el servidor antes de ejecutar docker compose"
          echo "üí° Puedes crearlo manualmente o copiarlo desde $ENV_DIR/.env si existe"
          if [ -f "$ENV_DIR/.env" ]; then
            echo "üìã Copiando .env desde $ENV_DIR/.env a $ENV_DIR/html/.env"
            cp "$ENV_DIR/.env" "$ENV_DIR/html/.env"
          else
            echo "‚ùå Error: No se encuentra .env en $ENV_DIR/.env ni en $ENV_DIR/html/.env"
            echo "‚ùå El despliegue no puede continuar sin el archivo .env"
            exit 1
          fi
        else
          echo "‚úÖ Archivo .env encontrado en $ENV_DIR/html/.env"
        fi
        
        # Verificar que existe credentials.json (cr√≠tico para GCS)
        if [ ! -f "credentials.json" ]; then
          echo "‚ö†Ô∏è  Advertencia: No se encuentra credentials.json en $ENV_DIR/html/credentials.json"
          echo "üí° El archivo credentials.json debe existir en el servidor para que GCS funcione"
          echo "üí° Puedes crearlo manualmente o copiarlo desde $ENV_DIR/credentials.json si existe"
          if [ -f "$ENV_DIR/credentials.json" ]; then
            echo "üìã Copiando credentials.json desde $ENV_DIR/credentials.json a $ENV_DIR/html/credentials.json"
            cp "$ENV_DIR/credentials.json" "$ENV_DIR/html/credentials.json"
            echo "‚úÖ credentials.json copiado desde $ENV_DIR/"
          else
            echo "‚ùå Error: No se encuentra credentials.json en $ENV_DIR/credentials.json ni en $ENV_DIR/html/credentials.json"
            echo "‚ùå El despliegue puede continuar pero GCS no funcionar√° sin credentials.json"
            echo "üí° Crea el archivo manualmente en $ENV_DIR/html/credentials.json antes de usar GCS"
          fi
        else
          echo "‚úÖ Archivo credentials.json encontrado en $ENV_DIR/html/credentials.json"
        fi
        
        # Verificar que POSTGRES_PASSWORD est√° definido en .env
        echo "üîç Verificando variables cr√≠ticas en .env..."
        if grep -q "^POSTGRES_PASSWORD=" .env 2>/dev/null; then
          echo "‚úÖ POSTGRES_PASSWORD encontrado en .env"
          # Leer POSTGRES_PASSWORD del .env
          POSTGRES_PASSWORD=$(grep "^POSTGRES_PASSWORD=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'")
        else
          echo "‚ö†Ô∏è  POSTGRES_PASSWORD no est√° definido en .env"
          echo "üîë Generando contrase√±a autom√°ticamente..."
          # Generar contrase√±a segura (25 caracteres alfanum√©ricos)
          POSTGRES_PASSWORD=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-25)
          echo "" >> .env
          echo "# PostgreSQL password (generado autom√°ticamente)" >> .env
          echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" >> .env
          echo "‚úÖ POSTGRES_PASSWORD generado y agregado al .env"
          echo "‚ö†Ô∏è  IMPORTANTE: Guarda esta contrase√±a en un lugar seguro"
          echo "üîë POSTGRES_PASSWORD=$POSTGRES_PASSWORD"
          echo "üí° Si ya existe una base de datos con otra contrase√±a, actualiza manualmente el .env"
        fi
        
        # Leer otras variables de PostgreSQL del .env o usar valores por defecto
        POSTGRES_USER=$(grep "^POSTGRES_USER=" .env 2>/dev/null | cut -d'=' -f2- | tr -d '"' | tr -d "'" || echo "atenea")
        POSTGRES_DB=$(grep "^POSTGRES_DB=" .env 2>/dev/null | cut -d'=' -f2- | tr -d '"' | tr -d "'" || echo "atenea_${ENV}")
        
        # Verificar y configurar DATABASE_URL (cr√≠tico para usar PostgreSQL, no SQLite)
        echo "üîç Verificando configuraci√≥n de DATABASE_URL..."
        if grep -q "^DATABASE_URL=" .env 2>/dev/null; then
          echo "‚úÖ DATABASE_URL encontrado en .env"
          DATABASE_URL=$(grep "^DATABASE_URL=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'")
          # Verificar que DATABASE_URL apunta a PostgreSQL
          if [[ ! "$DATABASE_URL" == postgresql://* ]]; then
            echo "‚ö†Ô∏è  Advertencia: DATABASE_URL no apunta a PostgreSQL, actualizando..."
            DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
            # Actualizar DATABASE_URL en .env
            sed -i "s|^DATABASE_URL=.*|DATABASE_URL=${DATABASE_URL}|" .env || echo "DATABASE_URL=${DATABASE_URL}" >> .env
            echo "‚úÖ DATABASE_URL actualizado a PostgreSQL"
          fi
        else
          echo "‚ö†Ô∏è  DATABASE_URL no est√° definido en .env"
          echo "üîß Configurando DATABASE_URL autom√°ticamente..."
          DATABASE_URL="postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}"
          echo "" >> .env
          echo "# Database URL (configurado autom√°ticamente)" >> .env
          echo "DATABASE_URL=${DATABASE_URL}" >> .env
          echo "‚úÖ DATABASE_URL configurado: postgresql://${POSTGRES_USER}:***@db:5432/${POSTGRES_DB}"
        fi
        
        # Asegurar que USE_SQLITE=False en todos los entornos (todos usan PostgreSQL)
        echo "üîç Verificando USE_SQLITE para entorno $ENV..."
        if grep -q "^USE_SQLITE=" .env 2>/dev/null; then
          USE_SQLITE_VALUE=$(grep "^USE_SQLITE=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'" | tr '[:upper:]' '[:lower:]')
          if [ "$USE_SQLITE_VALUE" == "true" ]; then
            echo "‚ö†Ô∏è  USE_SQLITE=True detectado en entorno $ENV, cambiando a False..."
            sed -i "s|^USE_SQLITE=.*|USE_SQLITE=False|" .env
            echo "‚úÖ USE_SQLITE actualizado a False"
          else
            echo "‚úÖ USE_SQLITE ya est√° en False"
          fi
        else
          echo "üîß Agregando USE_SQLITE=False al .env"
          echo "" >> .env
          echo "# Use PostgreSQL in all environments" >> .env
          echo "USE_SQLITE=False" >> .env
          echo "‚úÖ USE_SQLITE=False agregado al .env"
        fi
        
        # Asegurar que CELERY_BROKER_URL y CELERY_RESULT_BACKEND usen redis interno de Docker
        echo "üîç Verificando configuraci√≥n de Celery/Redis..."
        if grep -q "^CELERY_BROKER_URL=" .env 2>/dev/null; then
          CELERY_BROKER=$(grep "^CELERY_BROKER_URL=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'")
          if [[ ! "$CELERY_BROKER" == redis://redis:* ]] && [[ ! "$CELERY_BROKER" == redis://localhost:* ]]; then
            echo "‚ö†Ô∏è  CELERY_BROKER_URL no usa redis interno, actualizando..."
            sed -i "s|^CELERY_BROKER_URL=.*|CELERY_BROKER_URL=redis://redis:6379/0|" .env || echo "CELERY_BROKER_URL=redis://redis:6379/0" >> .env
            echo "‚úÖ CELERY_BROKER_URL actualizado a redis://redis:6379/0"
          fi
        else
          echo "üîß Agregando CELERY_BROKER_URL al .env"
          echo "CELERY_BROKER_URL=redis://redis:6379/0" >> .env
          echo "‚úÖ CELERY_BROKER_URL agregado"
        fi
        
        if grep -q "^CELERY_RESULT_BACKEND=" .env 2>/dev/null; then
          CELERY_RESULT=$(grep "^CELERY_RESULT_BACKEND=" .env | cut -d'=' -f2- | tr -d '"' | tr -d "'")
          if [[ ! "$CELERY_RESULT" == redis://redis:* ]] && [[ ! "$CELERY_RESULT" == redis://localhost:* ]]; then
            echo "‚ö†Ô∏è  CELERY_RESULT_BACKEND no usa redis interno, actualizando..."
            sed -i "s|^CELERY_RESULT_BACKEND=.*|CELERY_RESULT_BACKEND=redis://redis:6379/0|" .env || echo "CELERY_RESULT_BACKEND=redis://redis:6379/0" >> .env
            echo "‚úÖ CELERY_RESULT_BACKEND actualizado a redis://redis:6379/0"
          fi
        else
          echo "üîß Agregando CELERY_RESULT_BACKEND al .env"
          echo "CELERY_RESULT_BACKEND=redis://redis:6379/0" >> .env
          echo "‚úÖ CELERY_RESULT_BACKEND agregado"
        fi
        
        # Asegurar que CHANNEL_REDIS_URL est√© configurado para Django Channels
        if ! grep -q "^CHANNEL_REDIS_URL=" .env 2>/dev/null; then
          echo "üîß Agregando CHANNEL_REDIS_URL al .env"
          echo "CHANNEL_REDIS_URL=redis://redis:6379/1" >> .env
          echo "‚úÖ CHANNEL_REDIS_URL agregado"
        fi
        
        # Validar variables cr√≠ticas antes de continuar
        echo "üîç Validando variables cr√≠ticas..."
        MISSING_VARS=()
        for var in SECRET_KEY POSTGRES_PASSWORD POSTGRES_USER POSTGRES_DB GCS_BUCKET_NAME GCS_PROJECT_ID; do
          if ! grep -q "^${var}=" .env 2>/dev/null; then
            MISSING_VARS+=("$var")
          fi
        done
        
        if [ ${#MISSING_VARS[@]} -gt 0 ]; then
          echo "‚ùå Error: Faltan las siguientes variables cr√≠ticas en .env:"
          printf '  - %s\n' "${MISSING_VARS[@]}"
          exit 1
        fi
        echo "‚úÖ Todas las variables cr√≠ticas est√°n presentes"
        
        # Mostrar informaci√≥n del .env (sin mostrar valores sensibles)
        echo "üìã Variables definidas en .env (primeras 15):"
        grep -E "^[A-Z_]+=" .env | sed 's/=.*/=***/' | head -15 || echo "‚ö†Ô∏è  No se pudieron leer las variables del .env"
        
        echo "üõë Deteniendo y eliminando contenedores existentes"
        
        # Establecer nombre de proyecto √∫nico para evitar conflictos
        export COMPOSE_PROJECT_NAME="html-${ENV}"
        
        # Paso 1: Detener y eliminar usando docker compose (M√ÅS AGRESIVO)
        echo "‚è∏Ô∏è  Deteniendo contenedores con docker compose (proyecto: html-${ENV})..."
        # Usar --volumes para eliminar vol√∫menes tambi√©n si es necesario
        docker compose down --remove-orphans --volumes 2>/dev/null || true
        docker compose stop 2>/dev/null || true
        docker compose rm -f 2>/dev/null || true
        
        # Esperar un momento para que Docker procese las eliminaciones
        sleep 2
        
        # Paso 2: Eliminar contenedores espec√≠ficos por nombre exacto (m√°s agresivo)
        echo "üîç Eliminando contenedores espec√≠ficos del proyecto html-${ENV}..."
        # Lista de nombres de contenedores que pueden existir
        CONTAINER_NAMES=(
          "html-${ENV}-web-1"
          "html-${ENV}-db-1"
          "html-${ENV}-redis-1"
          "html-${ENV}-celery_worker-1"
          "html-${ENV}-celery_beat-1"
          "html-${ENV}-migrate-1"
          "html-${ENV}-collectstatic-1"
        )
        
        # Eliminar por nombre exacto primero
        for container_name in "${CONTAINER_NAMES[@]}"; do
          if docker ps -a --format "{{.Names}}" 2>/dev/null | grep -q "^${container_name}$"; then
            echo "üõë Eliminando contenedor espec√≠fico: $container_name"
            docker stop "$container_name" 2>/dev/null || true
            docker rm -f "$container_name" 2>/dev/null || true
          fi
        done
        
        # Tambi√©n buscar por patrones (por si hay variaciones)
        CONTAINER_PATTERNS=(
          "html-${ENV}-web-"
          "html-${ENV}-db-"
          "html-${ENV}-redis-"
          "html-${ENV}-celery_worker-"
          "html-${ENV}-celery_beat-"
          "html-${ENV}-migrate-"
          "html-${ENV}-collectstatic-"
        )
        
        for pattern in "${CONTAINER_PATTERNS[@]}"; do
          CONTAINERS=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^${pattern}" || echo "")
          if [ ! -z "$CONTAINERS" ]; then
            echo "$CONTAINERS" | while IFS= read -r container; do
              if [ ! -z "$container" ]; then
                echo "üõë Forzando eliminaci√≥n de: $container"
                docker stop "$container" 2>/dev/null || true
                docker rm -f "$container" 2>/dev/null || true
              fi
            done
          fi
        done
        
        # Paso 3: Eliminar contenedores hu√©rfanos que puedan tener nombres similares
        echo "üîç Eliminando contenedores hu√©rfanos..."
        ALL_CONTAINERS=$(docker ps -a --format "{{.Names}}" 2>/dev/null || echo "")
        if [ ! -z "$ALL_CONTAINERS" ]; then
          echo "$ALL_CONTAINERS" | while IFS= read -r container; do
            if [ ! -z "$container" ]; then
              # Buscar contenedores que coincidan con el patr√≥n del entorno
              if echo "$container" | grep -qE "^(html-${ENV}-|html-.*-${ENV}-)"; then
                echo "üõë Eliminando contenedor hu√©rfano: $container"
                docker stop "$container" 2>/dev/null || true
                docker rm -f "$container" 2>/dev/null || true
              fi
            fi
          done
        fi
        
        # Funci√≥n para eliminar contenedores de forma agresiva (legacy, por si acaso)
        cleanup_containers() {
          local pattern=$1
          echo "üîç Buscando contenedores con patr√≥n: $pattern"
          local containers=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^${pattern}" || echo "")
          if [ ! -z "$containers" ]; then
            echo "$containers" | while IFS= read -r container; do
              if [ ! -z "$container" ]; then
                echo "üõë Deteniendo contenedor: $container"
                docker stop "$container" 2>/dev/null || true
                echo "üóëÔ∏è  Eliminando contenedor: $container"
                docker rm -f "$container" 2>/dev/null || true
              fi
            done
          fi
        }
        
        # Paso 4: Limpiar redes hu√©rfanas (especialmente las del proyecto)
        echo "üßπ Limpiando redes hu√©rfanas..."
        # Eliminar redes espec√≠ficas del proyecto primero
        NETWORK_NAME="html-${ENV}_atenea-${ENV}-network"
        if docker network ls --format "{{.Name}}" 2>/dev/null | grep -q "^${NETWORK_NAME}$"; then
          echo "üóëÔ∏è  Eliminando red: $NETWORK_NAME"
          docker network rm "$NETWORK_NAME" 2>/dev/null || true
        fi
        # Limpiar todas las redes hu√©rfanas
        docker network prune -f 2>/dev/null || true
        
        # Paso 5: Verificaci√≥n final y eliminaci√≥n de cualquier contenedor restante
        echo "üîç Verificaci√≥n final: buscando contenedores restantes del proyecto..."
        sleep 2  # Esperar un momento m√°s para que Docker procese
        
        # Buscar contenedores que puedan causar conflictos
        REMAINING=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^(html-${ENV}-|html-.*-${ENV}-)" || echo "")
        if [ ! -z "$REMAINING" ]; then
          echo "‚ö†Ô∏è  A√∫n quedan contenedores, eliminando forzadamente:"
          echo "$REMAINING"
          echo "$REMAINING" | while IFS= read -r container; do
            if [ ! -z "$container" ]; then
              echo "üóëÔ∏è  Eliminando forzadamente: $container"
              docker stop "$container" 2>/dev/null || true
              docker rm -f "$container" 2>/dev/null || true
            fi
          done
          sleep 3
        else
          echo "  ‚úÖ Todos los contenedores conflictivos eliminados"
        fi
        
        # Verificaci√≥n final antes de continuar
        FINAL_CHECK=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^(html-${ENV}-web-|html-${ENV}-db-|html-${ENV}-redis-|html-${ENV}-celery)" || echo "")
        if [ ! -z "$FINAL_CHECK" ]; then
          echo "‚ùå ERROR: A√∫n existen contenedores que causar√°n conflictos:"
          echo "$FINAL_CHECK"
          echo "üîÑ Intentando eliminaci√≥n final..."
          echo "$FINAL_CHECK" | while IFS= read -r container; do
            if [ ! -z "$container" ]; then
              docker stop "$container" 2>/dev/null || true
              docker rm -f "$container" 2>/dev/null || true
            fi
          done
          sleep 2
        else
          echo "‚úÖ Verificaci√≥n final: No hay contenedores conflictivos"
        fi
        echo "üî® Construyendo y reiniciando contenedores"
        # Establecer nombre de proyecto √∫nico para evitar conflictos
        export COMPOSE_PROJECT_NAME="html-${ENV}"
        
        # Verificar una vez m√°s que no hay contenedores conflictivos antes de construir
        echo "üîç Verificaci√≥n pre-build: buscando contenedores conflictivos..."
        CONFLICT_CHECK=$(docker ps -a --format "{{.Names}}" 2>/dev/null | grep -E "^(html-${ENV}-web-|html-${ENV}-db-|html-${ENV}-redis-|html-${ENV}-celery)" || echo "")
        if [ ! -z "$CONFLICT_CHECK" ]; then
          echo "‚ö†Ô∏è  Advertencia: Encontrados contenedores conflictivos antes del build:"
          echo "$CONFLICT_CHECK"
          echo "üîÑ Eliminando..."
          echo "$CONFLICT_CHECK" | while IFS= read -r container; do
            if [ ! -z "$container" ]; then
              docker stop "$container" 2>/dev/null || true
              docker rm -f "$container" 2>/dev/null || true
            fi
          done
          sleep 2
        fi
        
        # Limpiar im√°genes hu√©rfanas antes de construir
        echo "üßπ Limpiando im√°genes hu√©rfanas..."
        docker image prune -f 2>/dev/null || true
        
        # Construir im√°genes
        echo "üî® Construyendo im√°genes Docker..."
        docker compose build --no-cache
        
        # Iniciar servicios (usar --force-recreate para asegurar que se recrean)
        echo "üöÄ Iniciando servicios..."
        docker compose up -d --force-recreate --remove-orphans
        
        echo "‚è≥ Esperando a que los servicios est√©n listos..."
        sleep 20
        
        # Verificar que los contenedores est√°n corriendo
        echo "üîç Verificando estado de contenedores..."
        RUNNING_CONTAINERS=$(docker compose ps --format json 2>/dev/null | jq -r '.[] | select(.State == "running") | .Name' 2>/dev/null || docker compose ps --format "{{.Name}}" | grep -v "^$" || echo "")
        if [ -z "$RUNNING_CONTAINERS" ]; then
          echo "‚ö†Ô∏è  Advertencia: No se detectaron contenedores corriendo, verificando logs..."
          docker compose ps
          docker compose logs --tail=50 web 2>/dev/null || true
        else
          echo "‚úÖ Contenedores corriendo:"
          echo "$RUNNING_CONTAINERS" | while IFS= read -r container; do
            if [ ! -z "$container" ]; then
              echo "  - $container"
            fi
          done
        fi
        
        # Verificar que la base de datos est√© accesible antes de ejecutar migraciones
        echo "üîç Verificando conexi√≥n a la base de datos..."
        MAX_RETRIES=10
        RETRY_COUNT=0
        while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
          if docker compose exec -T db pg_isready -U "${POSTGRES_USER}" > /dev/null 2>&1; then
            echo "‚úÖ Base de datos accesible"
            break
          else
            RETRY_COUNT=$((RETRY_COUNT + 1))
            echo "‚è≥ Esperando a que la base de datos est√© lista... (intento $RETRY_COUNT/$MAX_RETRIES)"
            sleep 3
          fi
        done
        
        if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
          echo "‚ùå Error: No se puede conectar a la base de datos despu√©s de $MAX_RETRIES intentos"
          exit 1
        fi
        
        # Verificar que la base de datos existe, si no, crearla
        echo "üîç Verificando que la base de datos existe..."
        DB_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -lqt 2>/dev/null | cut -d \| -f 1 | grep -w "${POSTGRES_DB}" | wc -l || echo "0")
        if [ "$DB_EXISTS" == "0" ]; then
          echo "‚ö†Ô∏è  La base de datos ${POSTGRES_DB} no existe, cre√°ndola..."
          docker compose exec -T db psql -U "${POSTGRES_USER}" -c "CREATE DATABASE ${POSTGRES_DB};" postgres || {
            echo "‚ùå Error al crear la base de datos"
            exit 1
          }
          echo "‚úÖ Base de datos ${POSTGRES_DB} creada"
        else
          echo "‚úÖ Base de datos ${POSTGRES_DB} existe"
        fi
        
        # Asegurar que COMPOSE_PROJECT_NAME est√© configurado para las operaciones siguientes
        export COMPOSE_PROJECT_NAME="html-${ENV}"
        
        # ============================================
        # EJECUTAR MIGRACIONES (SIEMPRE)
        # ============================================
        # Las migraciones se ejecutan SIEMPRE, sin importar el estado de la BD
        # Django maneja autom√°ticamente si las migraciones ya est√°n aplicadas o no
        echo "üîÑ Ejecutando migraciones de Django..."
        echo "üìã Esto crear√° todas las tablas necesarias si la BD est√° vac√≠a, o aplicar√° migraciones pendientes si ya existen tablas"
        
        # Ejecutar migraciones con reintentos
        MAX_MIGRATION_RETRIES=3
        MIGRATION_RETRY_COUNT=0
        MIGRATION_SUCCESS=false
        
        while [ $MIGRATION_RETRY_COUNT -lt $MAX_MIGRATION_RETRIES ] && [ "$MIGRATION_SUCCESS" != "true" ]; do
          MIGRATION_RETRY_COUNT=$((MIGRATION_RETRY_COUNT + 1))
          echo "üîÑ Intento de migraci√≥n $MIGRATION_RETRY_COUNT/$MAX_MIGRATION_RETRIES..."
          
          MIGRATION_OUTPUT=$(docker compose run --rm web python manage.py migrate --noinput 2>&1)
          MIGRATION_EXIT_CODE=$?
          
          echo "$MIGRATION_OUTPUT"
          
          if [ $MIGRATION_EXIT_CODE -eq 0 ]; then
            echo "‚úÖ Migraciones ejecutadas correctamente"
            MIGRATION_SUCCESS=true
          else
            echo "‚ö†Ô∏è  Las migraciones fallaron con c√≥digo $MIGRATION_EXIT_CODE (intento $MIGRATION_RETRY_COUNT/$MAX_MIGRATION_RETRIES)"
            if [ $MIGRATION_RETRY_COUNT -lt $MAX_MIGRATION_RETRIES ]; then
              echo "‚è≥ Esperando 5 segundos antes de reintentar..."
              sleep 5
            fi
          fi
        done
        
        if [ "$MIGRATION_SUCCESS" != "true" ]; then
          echo "‚ùå Error: Las migraciones fallaron despu√©s de $MAX_MIGRATION_RETRIES intentos"
          echo "üîç Verificando estado de la base de datos..."
          docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -c "\dt" 2>/dev/null || true
          echo "üìã √öltimas l√≠neas de logs del contenedor web:"
          docker compose logs web 2>/dev/null | tail -30 || true
          exit 1
        fi
        
        # Verificar que las tablas principales de Django existen despu√©s de las migraciones
        echo "üîç Verificando que las tablas principales existen..."
        REQUIRED_TABLES=("django_migrations" "django_session" "auth_user" "core_project")
        MISSING_TABLES=()
        
        for table in "${REQUIRED_TABLES[@]}"; do
          TABLE_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name='${table}');" 2>/dev/null | tr -d '[:space:]' || echo "f")
          if [ "$TABLE_EXISTS" != "t" ]; then
            MISSING_TABLES+=("$table")
          fi
        done
        
        if [ ${#MISSING_TABLES[@]} -gt 0 ]; then
          echo "‚ùå Error: Faltan las siguientes tablas despu√©s de las migraciones: ${MISSING_TABLES[*]}"
          echo "üìã Estado actual de la base de datos:"
          docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -c "\dt" 2>/dev/null || true
          echo "üìã √öltimas l√≠neas de logs del contenedor web:"
          docker compose logs web 2>/dev/null | tail -30 || true
          exit 1
        else
          echo "‚úÖ Todas las tablas principales existen correctamente"
        fi
        
        # Verificar que las tablas principales de Django existen
        echo "üîç Verificando que las tablas principales existen..."
        REQUIRED_TABLES=("django_migrations" "django_session" "auth_user" "core_project")
        MISSING_TABLES=()
        
        for table in "${REQUIRED_TABLES[@]}"; do
          TABLE_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name='${table}');" 2>/dev/null | tr -d '[:space:]' || echo "f")
          if [ "$TABLE_EXISTS" != "t" ]; then
            MISSING_TABLES+=("$table")
          fi
        done
        
        if [ ${#MISSING_TABLES[@]} -gt 0 ]; then
          echo "‚ö†Ô∏è  Advertencia: Faltan las siguientes tablas: ${MISSING_TABLES[*]}"
          echo "üîÑ Ejecutando migraciones nuevamente para crear las tablas faltantes..."
          sleep 5
          if docker compose run --rm migrate; then
            echo "‚úÖ Migraciones ejecutadas nuevamente"
            # Verificar nuevamente
            for table in "${MISSING_TABLES[@]}"; do
              TABLE_EXISTS=$(docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -t -c "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name='${table}');" 2>/dev/null | tr -d '[:space:]' || echo "f")
              if [ "$TABLE_EXISTS" == "t" ]; then
                echo "‚úÖ Tabla ${table} creada correctamente"
              else
                echo "‚ùå Error: La tabla ${table} a√∫n no existe despu√©s de las migraciones"
                exit 1
              fi
            done
          else
            echo "‚ùå Error: No se pudieron crear las tablas faltantes"
            echo "üìã Estado actual de la base de datos:"
            docker compose exec -T db psql -U "${POSTGRES_USER}" -d "${POSTGRES_DB}" -c "\dt" || true
            exit 1
          fi
        else
          echo "‚úÖ Todas las tablas principales existen"
        fi
        
        echo "üì¶ Recolectando archivos est√°ticos"
        if docker compose run --rm collectstatic; then
          echo "‚úÖ Archivos est√°ticos recolectados correctamente"
        else
          echo "‚ö†Ô∏è  Advertencia: Error en collectstatic (no cr√≠tico, continuando...)"
        fi
        
        # Verificar que los servicios cr√≠ticos est√°n funcionando
        echo "üîç Verificando servicios cr√≠ticos..."
        
        # Verificar Redis
        echo "  üîç Verificando Redis..."
        if docker compose exec -T redis redis-cli ping > /dev/null 2>&1; then
          echo "  ‚úÖ Redis est√° funcionando"
        else
          echo "  ‚ö†Ô∏è  Advertencia: Redis no responde (puede necesitar m√°s tiempo)"
        fi
        
        # Verificar PostgreSQL
        echo "  üîç Verificando PostgreSQL..."
        if docker compose exec -T db pg_isready -U "${POSTGRES_USER}" > /dev/null 2>&1; then
          echo "  ‚úÖ PostgreSQL est√° funcionando"
        else
          echo "  ‚ö†Ô∏è  Advertencia: PostgreSQL no responde (puede necesitar m√°s tiempo)"
        fi
        
        # Verificar Celery Worker
        echo "  üîç Verificando Celery Worker..."
        CELERY_WORKER=$(docker compose ps --format "{{.Name}}" | grep celery_worker || echo "")
        if [ ! -z "$CELERY_WORKER" ]; then
          if docker compose ps --format "{{.State}}" | grep -q "running" | grep celery_worker; then
            echo "  ‚úÖ Celery Worker est√° corriendo"
          else
            echo "  ‚ö†Ô∏è  Advertencia: Celery Worker no est√° corriendo"
          fi
        else
          echo "  ‚ö†Ô∏è  Advertencia: No se encontr√≥ contenedor de Celery Worker"
        fi
        
        # Verificar Celery Beat
        echo "  üîç Verificando Celery Beat..."
        CELERY_BEAT=$(docker compose ps --format "{{.Name}}" | grep celery_beat || echo "")
        if [ ! -z "$CELERY_BEAT" ]; then
          if docker compose ps --format "{{.State}}" | grep -q "running" | grep celery_beat; then
            echo "  ‚úÖ Celery Beat est√° corriendo"
          else
            echo "  ‚ö†Ô∏è  Advertencia: Celery Beat no est√° corriendo"
          fi
        else
          echo "  ‚ö†Ô∏è  Advertencia: No se encontr√≥ contenedor de Celery Beat"
        fi
        
        # Verificar Web
        echo "  üîç Verificando Web..."
        WEB_CONTAINER=$(docker compose ps --format "{{.Name}}" | grep -E "^html-.*-web-" || echo "")
        if [ ! -z "$WEB_CONTAINER" ]; then
          WEB_STATE=$(docker compose ps --format "{{.State}}" | head -1 || echo "")
          if echo "$WEB_STATE" | grep -q "running"; then
            echo "  ‚úÖ Web est√° corriendo"
          else
            echo "  ‚ö†Ô∏è  Advertencia: Web no est√° corriendo (estado: $WEB_STATE)"
            echo "  üìã √öltimas l√≠neas de logs de web:"
            docker compose logs --tail=20 web 2>/dev/null || true
          fi
        else
          echo "  ‚ö†Ô∏è  Advertencia: No se encontr√≥ contenedor de Web"
        fi
        
        echo ""
        echo "‚úÖ Despliegue a $ENV completado!"
        echo ""
        echo "üìä Resumen del despliegue:"
        echo "  - Entorno: $ENV"
        echo "  - Base de datos: ${POSTGRES_DB}"
        echo "  - Usuario DB: ${POSTGRES_USER}"
        echo "  - Directorio: $ENV_DIR/html"
        if [ "$ENV" == "prod" ]; then
          echo "  - URL: https://atenea.nxhumans.com"
        else
          echo "  - URL: https://$ENV.atenea.nxhumans.com"
        fi
        echo ""
        echo "üí° Para ver logs: cd $ENV_DIR/html && docker compose logs -f"
        echo "üí° Para ver estado: cd $ENV_DIR/html && docker compose ps"
        DEPLOY_SCRIPT
