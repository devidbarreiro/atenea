# MigraciÃ³n a LangGraph - Overview TÃ©cnico

## ğŸ“‹ Resumen Ejecutivo

Estamos migrando de **n8n** (workflow externo) a **LangGraph** (agente propio integrado) para el procesamiento de guiones. Esta migraciÃ³n nos da:

- âœ… **Control total** sobre el proceso
- âœ… **Observabilidad completa** (LangSmith + Django)
- âœ… **Costos reducidos** (sin dependencia externa)
- âœ… **Velocidad mejorada** (procesamiento sÃ­ncrono)
- âœ… **Escalabilidad** (nuestro propio cÃ³digo)

---

## 1. âœ… ConfiguraciÃ³n de API Keys

**Estado:** âœ… **COMPLETO**

- Claves configuradas en `.env` para OpenAI y Gemini
- Sistema de fallback automÃ¡tico si un proveedor falla
- Factory pattern (`LLMFactory`) para crear instancias LLM
- Soporte para mÃºltiples modelos por proveedor

**UbicaciÃ³n:** `core/llm/factory.py`

---

## 2. âœ… Variables de Entorno

**Estado:** âœ… **COMPLETO**

- Todas las API keys en `.env`
- Sistema robusto que lee de Django settings o variables de entorno
- Funciona incluso cuando Django no estÃ¡ inicializado (Ãºtil para notebooks)

---

## 3. ğŸ¯ LangGraph vs LangChain: Â¿CuÃ¡l usar?

### **LangGraph** (Recomendado para tu caso) âœ…

**QuÃ© es:** Framework para construir **grafos de agentes** con estado persistente y control de flujo.

**Ventajas para tu soluciÃ³n:**
- âœ… **Grafos visuales** - FÃ¡cil de entender y depurar
- âœ… **Estado compartido** - Mantiene contexto entre nodos
- âœ… **Control de flujo** - Edges condicionales, loops, human-in-the-loop
- âœ… **Persistencia** - Puede guardar estado entre ejecuciones
- âœ… **Streaming** - Ver el progreso en tiempo real
- âœ… **Perfecto para workflows complejos** como tu proceso de guiones

**CuÃ¡ndo usar:** Cuando necesitas un **flujo de trabajo con mÃºltiples pasos** y decisiones.

### **LangChain** (Base)

**QuÃ© es:** Framework para construir aplicaciones LLM con chains, tools, y memory.

**Ventajas:**
- âœ… MÃ¡s simple para casos bÃ¡sicos
- âœ… Mejor para single-shot prompts
- âœ… MÃ¡s documentaciÃ³n y ejemplos

**CuÃ¡ndo usar:** Para prompts simples sin flujo complejo.

### **RecomendaciÃ³n para tu caso:**

**Usa LangGraph** porque:
1. Tu proceso tiene **mÃºltiples pasos** (analizar â†’ parsear â†’ validar â†’ corregir â†’ formatear)
2. Necesitas **validaciones condicionales** (si hay errores, corregir automÃ¡ticamente)
3. Quieres **observabilidad** del flujo completo
4. Planeas aÃ±adir **human-in-the-loop** en el futuro

**Nota:** LangGraph estÃ¡ construido sobre LangChain, asÃ­ que puedes usar ambas juntas.

---

## 4. ğŸ› ï¸ Herramientas (Tools) Interesantes

### Ya implementadas:
- âœ… **ValidaciÃ³n de duraciones** (`duration_validator`)
- âœ… **ValidaciÃ³n de estructura JSON** (`json_validator`)
- âœ… **CorrecciÃ³n automÃ¡tica** (`auto_corrector`)
- âœ… **ValidaciÃ³n platform/avatar** (`platform_selector`)

### Herramientas adicionales recomendadas:

#### **BÃºsqueda y Web Scraping:**
- `TavilySearchResults` - BÃºsqueda web para contexto
- `DuckDuckGoSearchRun` - BÃºsqueda sin API key
- `ArxivSearch` - BÃºsqueda acadÃ©mica

#### **AnÃ¡lisis de Texto:**
- `TextSplitter` - Dividir guiones largos
- `SemanticSimilarity` - Encontrar guiones similares
- `SentimentAnalysis` - AnÃ¡lisis de sentimiento

#### **ValidaciÃ³n Avanzada:**
- `SchemaValidator` - Validar contra JSON Schema
- `ContentModerator` - Moderar contenido inapropiado
- `LanguageDetector` - Detectar idioma del guiÃ³n

#### **Integraciones Externas:**
- `GoogleSearch` - BÃºsqueda con Google API
- `Wikipedia` - Consultar Wikipedia
- `YouTubeTranscript` - Obtener transcripciones

**RecomendaciÃ³n:** Empieza con las que ya tienes. AÃ±ade mÃ¡s segÃºn necesidades especÃ­ficas.

---

## 5. ğŸ“Š Observabilidad: QuÃ© Trackear

### Ya implementado:
- âœ… **LangSmith** - Traces completos de ejecuciÃ³n
- âœ… **Django Logging** - Logs estructurados

### MÃ©tricas adicionales recomendadas:

#### **Performance:**
- â±ï¸ **Latencia por nodo** - Tiempo de cada paso
- ğŸ”„ **Throughput** - Requests por minuto
- âš¡ **Cache hit rate** - Eficiencia del cachÃ©

#### **Calidad:**
- âœ… **Tasa de Ã©xito** - % de requests exitosas
- ğŸ” **Tasa de retry** - CuÃ¡ntas veces necesita reintentar
- ğŸ¯ **Calidad de respuesta** - Score de calidad (LLM eval)

#### **Costos:**
- ğŸ’° **Costo por request** - USD por guiÃ³n procesado
- ğŸ“ˆ **Costo diario/mensual** - Tracking acumulado
- ğŸ” **Costo por proveedor** - Comparar OpenAI vs Gemini

#### **Errores:**
- âŒ **Tipos de error** - ClasificaciÃ³n de errores
- ğŸ” **Errores por nodo** - DÃ³nde falla mÃ¡s
- ğŸ“Š **Tendencias de error** - Errores a lo largo del tiempo

**Herramientas recomendadas:**
- **LangSmith** (ya tienes) - Traces y debugging
- **Prometheus + Grafana** - MÃ©tricas en tiempo real
- **Sentry** - Alertas de errores
- **Datadog** - APM completo (si tienes presupuesto)

---

## 6. ğŸ“ˆ Tracking Detallado

### Ya implementado:
- âœ… Tokens (input/output) - `AgentMetrics.track_request()`
- âœ… Costos estimados - `LLMFactory.get_cost_estimate()`
- âœ… Latencia bÃ¡sica

### Mejoras recomendadas:

#### **Tracking de Tokens:**
```python
# Ya tienes esto en AgentMetrics
input_tokens, output_tokens, total_tokens
```

#### **Tracking de Latencia:**
```python
# AÃ±adir latencia por nodo
latency_by_node = {
    'analyze_script': 2.5,
    'parse_response': 0.1,
    'validate_output': 0.3,
    'auto_correct': 1.2,
    'format_output': 0.05
}
```

#### **Tracking de Costos:**
```python
# Ya tienes costo por request
# AÃ±adir: costo acumulado diario/mensual
daily_cost = sum(costs_today)
monthly_cost = sum(costs_this_month)
```

#### **Tracking de Errores:**
```python
error_types = {
    'json_parse_error': 5,
    'validation_error': 12,
    'llm_timeout': 2,
    'api_error': 1
}
```

#### **Tracking de Retries:**
```python
retry_stats = {
    'total_retries': 8,
    'retries_by_node': {
        'analyze_script': 3,
        'validate_output': 5
    },
    'avg_retries_per_request': 0.4
}
```

#### **Calidad de Respuestas:**
```python
# Evaluar calidad con LLM
quality_score = evaluate_response_quality(response)
# O mÃ©tricas simples:
- Completeness: Â¿Tiene todos los campos?
- Correctness: Â¿Pasa validaciones?
- Consistency: Â¿Es consistente con otros guiones?
```

**RecomendaciÃ³n:** Implementa gradualmente. Empieza con lo bÃ¡sico (ya lo tienes) y aÃ±ade mÃ©tricas segÃºn necesidades.

---

## 7. ğŸ”„ n8n: Estado Actual

**Estado:** âœ… **DEPRECADO pero conservado**

- CÃ³digo comentado para referencia histÃ³rica
- Ya no se usa en producciÃ³n
- Formato de respuesta mantenido para compatibilidad
- `create_scenes_from_n8n_data()` sigue funcionando (formato compatible)

**Ventajas de mantener el formato:**
- âœ… Compatibilidad con cÃ³digo existente
- âœ… MigraciÃ³n gradual sin romper nada
- âœ… Referencia para entender estructura esperada

**RecomendaciÃ³n:** Mantener formato compatible hasta que toda la migraciÃ³n estÃ© completa.

---

## 8. ğŸ” Sistema de Retry

**Estado actual:** âœ… **Implementado**

- Retry a nivel de agente (`max_retries=2`)
- Retry automÃ¡tico si falla un nodo
- CorrecciÃ³n automÃ¡tica antes de retry

**RecomendaciÃ³n:** 
- âœ… **Mantener retry propio** - MÃ¡s control
- âœ… **AÃ±adir exponential backoff** - Esperar mÃ¡s entre retries
- âœ… **Retry inteligente** - Solo retry errores recuperables (no errores de validaciÃ³n lÃ³gica)

**Ejemplo mejorado:**
```python
def should_retry(error):
    retryable_errors = ['timeout', 'rate_limit', 'api_error']
    return any(e in str(error).lower() for e in retryable_errors)
```

---

## 9. ğŸ“¤ Respuesta Completa

**Estado:** âœ… **Correcto**

- Respuesta completa con `project`, `characters`, `scenes`
- Formato compatible con n8n
- Incluye mÃ©tricas y correcciones aplicadas

**RecomendaciÃ³n:** Mantener formato actual. Es simple y funcional.

---

## 10. ğŸ’¾ Sistema de CachÃ©

### **CÃ³mo funciona actualmente:**

Ya tienes `AgentCache` implementado en `core/agents/cache.py`:

```python
# Guardar respuesta
AgentCache.set(script_text, duration_min, response)

# Obtener respuesta cacheada
cached = AgentCache.get(script_text, duration_min)
```

**CÃ³mo funciona:**
1. **Hash del contenido** - Crea hash SHA256 de `script_text + duration_min`
2. **Redis/Django Cache** - Guarda respuesta en cachÃ©
3. **TTL** - Expira despuÃ©s de 24 horas (configurable)
4. **Cache hit** - Si mismo guiÃ³n + duraciÃ³n â†’ retorna cacheado

### **Recomendaciones:**

#### **Estrategia de CachÃ©:**
- âœ… **Cache por contenido** - Ya implementado (hash del guiÃ³n)
- âœ… **TTL configurable** - Ya implementado
- âš ï¸ **Cache warming** - Pre-cachear guiones comunes
- âš ï¸ **Cache invalidation** - Invalidar cuando prompt cambia

#### **Backend de CachÃ©:**
- âœ… **Redis** (recomendado) - RÃ¡pido, persistente, escalable
- âš ï¸ **Django Cache** (fallback) - Funciona pero menos eficiente

#### **Mejoras sugeridas:**
1. **Cache por versiÃ³n de prompt** - Si cambias el prompt, invalidar cachÃ©
2. **Cache inteligente** - Cachear solo guiones > X caracteres (evitar cachear tests)
3. **Cache stats** - Trackear hit rate para optimizar

**Ejemplo mejorado:**
```python
def get_cache_key(script_text, duration_min, prompt_version):
    content = f"{script_text}:{duration_min}:{prompt_version}"
    return hashlib.sha256(content.encode()).hexdigest()
```

---

## 11. ğŸš¦ Rate Limiting: Establecer LÃ­mites

### **CÃ³mo establecer lÃ­mites bien:**

#### **1. Analizar uso actual:**
```python
# Trackear durante 1-2 semanas:
- Requests por dÃ­a
- Tokens por dÃ­a
- Costo por dÃ­a
- Picos de uso (horas del dÃ­a)
```

#### **2. Calcular lÃ­mites razonables:**
```python
# Ejemplo:
daily_avg = 1000 requests/day
peak_hour = 200 requests/hour
safety_margin = 1.5x

daily_limit = daily_avg * safety_margin  # 1500/day
hourly_limit = peak_hour * safety_margin  # 300/hour
```

#### **3. LÃ­mites por tipo de usuario:**
```python
limits = {
    'free': {
        'monthly_tokens': 100_000,
        'daily_requests': 10
    },
    'pro': {
        'monthly_tokens': 1_000_000,
        'daily_requests': 100
    },
    'enterprise': {
        'monthly_tokens': 10_000_000,
        'daily_requests': 1000
    }
}
```

#### **4. LÃ­mites por proveedor:**
```python
provider_limits = {
    'openai': {
        'tpm': 50000,  # tokens per minute
        'rpm': 500     # requests per minute
    },
    'gemini': {
        'tpm': 100000,
        'rpm': 1000
    }
}
```

#### **5. ImplementaciÃ³n recomendada:**
- âœ… **Redis counters** - Contadores en Redis (ya tienes Redis)
- âœ… **Sliding window** - Ventana deslizante para lÃ­mites por hora
- âœ… **Graceful degradation** - Si lÃ­mite alcanzado, usar proveedor alternativo
- âœ… **Alertas** - Notificar cuando se acerca al lÃ­mite

**RecomendaciÃ³n:** Empieza con lÃ­mites generosos y ajusta segÃºn uso real.

---

## 12. âœ… Validaciones y CorrecciÃ³n AutomÃ¡tica

**Estado:** âœ… **Bien implementado**

- ValidaciÃ³n de estructura JSON
- ValidaciÃ³n de duraciones
- ValidaciÃ³n de consistencia platform/avatar
- CorrecciÃ³n automÃ¡tica de errores
- Reintento despuÃ©s de correcciÃ³n

**RecomendaciÃ³n:** Mantener como estÃ¡. Funciona bien.

---

## 13. ğŸ¤” Punto 13: Â¿QuÃ© no entiendes?

**Necesito mÃ¡s contexto** sobre quÃ© punto especÃ­fico no entiendes. Â¿Es sobre:
- Human-in-the-loop?
- Persistencia de estado?
- Streaming?
- Algo mÃ¡s?

**Dime quÃ© punto especÃ­fico y te explico mejor.**

---

## 14. ğŸ“ Versionado de Prompts y A/B Testing

### **Versionado de Prompts:**

**Por quÃ© es importante:**
- âœ… Comparar resultados entre versiones
- âœ… Rollback si nueva versiÃ³n empeora
- âœ… Tracking de quÃ© versiÃ³n generÃ³ quÃ© resultado

**ImplementaciÃ³n recomendada:**

```python
# En settings.py
PROMPT_VERSION = 'v1.2.3'

# En el prompt
prompt = f"""
[Version: {settings.PROMPT_VERSION}]
{base_prompt}
"""

# En cachÃ©
cache_key = f"{script_hash}:{PROMPT_VERSION}"
```

**Sistema de versionado:**
- `v1.0.0` - VersiÃ³n inicial
- `v1.1.0` - Cambios menores (mejoras de claridad)
- `v1.2.0` - Cambios mayores (nuevas instrucciones)
- `v2.0.0` - Cambios significativos (restructuraciÃ³n)

### **A/B Testing:**

**CÃ³mo funciona:**
1. **Dividir trÃ¡fico** - 50% versiÃ³n A, 50% versiÃ³n B
2. **Trackear mÃ©tricas** - Calidad, costo, latencia
3. **Comparar resultados** - Â¿CuÃ¡l es mejor?
4. **Decidir ganador** - Implementar versiÃ³n ganadora

**ImplementaciÃ³n:**

```python
def get_prompt_version(user_id):
    # Deterministic A/B test basado en user_id
    if hash(user_id) % 2 == 0:
        return 'v1.2.0'  # VersiÃ³n A
    else:
        return 'v1.3.0'  # VersiÃ³n B

# Trackear quÃ© versiÃ³n se usÃ³
metrics['prompt_version'] = prompt_version
metrics['ab_test_group'] = 'A' if prompt_version == 'v1.2.0' else 'B'
```

**MÃ©tricas a comparar:**
- âœ… Tasa de Ã©xito
- âœ… Calidad de respuesta (LLM eval)
- âœ… Costo promedio
- âœ… Latencia promedio
- âœ… Tasa de retry

**RecomendaciÃ³n:** 
- âœ… Implementar versionado primero (simple)
- âœ… A/B testing despuÃ©s (mÃ¡s complejo, pero muy valioso)

---

## ğŸ“Š Resumen: Estado Actual vs Recomendaciones

| Aspecto | Estado Actual | RecomendaciÃ³n |
|---------|---------------|---------------|
| **API Keys** | âœ… Configuradas | Mantener |
| **LangGraph** | âœ… Implementado | âœ… Correcto |
| **Herramientas** | âœ… BÃ¡sicas | AÃ±adir segÃºn necesidad |
| **Observabilidad** | âœ… LangSmith + Logs | AÃ±adir mÃ©tricas detalladas |
| **Tracking** | âœ… BÃ¡sico | Expandir gradualmente |
| **n8n** | âœ… Deprecado | Mantener formato compatible |
| **Retry** | âœ… Implementado | Mejorar con backoff |
| **CachÃ©** | âœ… Implementado | AÃ±adir versionado de prompt |
| **Rate Limiting** | âš ï¸ Pendiente | Implementar con Redis |
| **Validaciones** | âœ… Completas | Mantener |
| **Versionado** | âš ï¸ Pendiente | Implementar pronto |
| **A/B Testing** | âš ï¸ Pendiente | DespuÃ©s de versionado |

---

## ğŸ¯ PrÃ³ximos Pasos Recomendados

1. **Corto plazo (1-2 semanas):**
   - âœ… Implementar versionado de prompts
   - âœ… Mejorar tracking de mÃ©tricas
   - âœ… AÃ±adir rate limiting bÃ¡sico

2. **Medio plazo (1 mes):**
   - âœ… A/B testing de prompts
   - âœ… Dashboard de mÃ©tricas
   - âœ… Alertas automÃ¡ticas

3. **Largo plazo (2-3 meses):**
   - âœ… OptimizaciÃ³n de cachÃ©
   - âœ… AnÃ¡lisis de calidad avanzado
   - âœ… Auto-tuning de prompts

---

## ğŸ“š DocumentaciÃ³n de Referencia

- **LangGraph Docs:** https://docs.langchain.com/oss/python/langgraph/
- **LangSmith:** https://docs.smith.langchain.com/
- **Django Caching:** https://docs.djangoproject.com/en/stable/topics/cache/
- **Redis Rate Limiting:** https://redis.io/docs/manual/patterns/rate-limiting/

